#this script categorizes PA events as a function of the number of BA, FA, and VA events which precede them. It epochs them, extracts ERPS, and plots them. 
#current working version
#10/15/2024: 

import pathlib
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import mne

# define protocol and onset type
protocol = 'protocol02'
onset_type = 'consonant'          # 'vowel' or 'consonant' depending on where 0 for the trigger is
date = 'October 22'   
debugging = False
trigger_position = 0.00         # change this value to shift away from onset
plot_raw = False
ICA = True                  # run ICA on raw data   OR
ICA_variance = .97                # either percent e.g. .95 or number of components e.g., 40
display_ica_plots = True        # allows for ICA componants to be viewed, if set to false ICA will just run according to predetermiend component selection
reject_bad_epochs = True
dropped_epoch_logging = False   #shows logs for dropped epochs
interpolate_bads = True
resample_evoked = True
resample_rate = 250
baseline = (None, 0)            # means from the first instant to t = 0
plot_show=False

# Define the parameters for the filter
l_freq = .1
h_freq = 30

# Define the time limits for the epochs
tmin = -0.1
tmax = 0.8 

# define the parameters for bad epochs
reject_criteria = dict(mag=3000e-15) 
flat_criteria = dict(mag=1e-15) 


# list of participant IDs
participant_ids = ['R3027', #1 
                   'R3039', #2 
                   'R3401', #3 
                   'R3703', #4 
                   'R3078', #5 
                   'R3079', #6 
                   'R3086', #7 
                   'R3090', #8 
                   'R3109', #9 
                   'R3112', #10 
                   'R3113', #11 
                   'R3117', #12 
                   'R3120', #13 
                   'R3124', #14 this data is kind of strange, like they had a small head or it wasn't placed correctly
                   'R3126'  #15 
                  ]

n = 'n=' + str(len(participant_ids))
# bad channels dictionary 
#dead_channel = ['MEG 056'] #this channel has bad coordinates. it is also dead for part 01. if you ever can get the coordinates you can try interpolating it
bad_channels = ['MEG 086'] #86 is always bad, but it can be interpolated

# components to exclude during ICA
participant_components = {
    #'R3027': [0, 1, 2, 3, 4, 5, 6, 9, 14, 18, 20], #21 components 15?
    #'R3039': [0, 1, 2, 3, 4, 11, 12, 13 14], #15 components
    #'R3401': [0, 1, 3, 4, 8, 10, 19, 24, 25, 26, 27, 28, 29], #30 components
    #'R3703': [0, 1, 2, 3, 8, 9, 23, 24, 25, 26, 27], #28 components 5
    'R3078': [0, 1, 2, 3, 5, 7, 9, 11, 13, 14, 18], #20 components 19
    #'R3079': [0, 1, 2, 3, 8, 10, 15, 11, 13, 14, 16, 18, 17, 19, 20], #21 components 6
    #'R3086': [0, 1, 2, 3, 5, 6, 14, 17, 19, 23, 24, 25, 26, 27],# 28 components
    #'R3090': [0, 1, 2, 3, 4, 5, 6, 7, 10, 15, 20, 21, 23, 24, 25, 26], #27 components 8
   # 'R3109': [0, 1, 2, 9, 11, 14, 16, 17, 18, 20, 21, 22, 23], #24 components
   # 'R3112': [0, 1, 2, 3, 4, 6, 9, 13, 19, 18, 20, 21], #22 components
   # 'R3113': [0, 1, 2, 3, 4, 5, 6, 7, 17, 19, 20, 22, 23, 24, 21], #25 components
    #'R3117': [0, 1, 2, 3, 5, 6, 7, 8, 10, 15, 16, 17, 18, 19, 20, 21, 22], #23 components
   # 'R3120': [0, 1, 5, 12, 13, 16, 23, 22, 21], #24 components
   # 'R3124': [0, 1, 2, 6, 3, 5, 12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], # 29 components
   # 'R3126': [0, 1, 2, 3, 13, 17, 20, 21, 23, 25, 26, 27, 28], #29 components
}

idiosyncratic_bads = {
    'R3027': ['MEG 056'], 
    'R3039': ['MEG 056'],
    'R3401': ['MEG 056'], 
    'R3703': ['MEG 056'],
    'R3078': ['MEG 056'],
    'R3079': ['MEG 056'],
    'R3086': ['MEG 056'], 
    'R3090': ['MEG 056'], 
    'R3109': ['MEG 056', 'MEG 105'], 
    'R3112': ['MEG 056'],
    'R3113': ['MEG 056'], 
    'R3117': ['MEG 056', 'MEG 117'], 
    'R3120': ['MEG 056', 'MEG 117'], 
    'R3124': ['MEG 056', 'MEG 117'], 
    'R3126': ['MEG 056'],
    
}



# don't change below unless permanent
# Define trigger shifts based on onset type
def calculate_shifts(onset_type):
    if onset_type == 'vowel':
        bashift = 0.190-trigger_position
        pashift = 0.108-trigger_position
        fashift = 0.183-trigger_position
        vashift = 0.197-trigger_position
    elif onset_type == 'consonant':
        bashift = 0.157-trigger_position
        pashift = 0.033-trigger_position 
        fashift = 0.062-trigger_position 
        vashift = 0.156-trigger_position
    else:
        raise ValueError("Problem, neither 'vowel' nor 'consonant'.")
    return bashift, pashift, fashift, vashift

# define file names for saving based on ICA variable
ICA_file = "ICA" if ICA else ""
reject_file = "bad_epochs_rejected" if reject_bad_epochs else ""
dataset = 'V_onset' if onset_type == 'vowel' else 'C_onset'

# Load data directory
data_dir = pathlib.Path(f'../../all data/{protocol}')
# Ensure the output directory exists
output_dir = pathlib.Path(f'../../out_data/{protocol}/{dataset}')
output_dir.mkdir(parents=True, exist_ok=True)
# Create the directory to store the plots
plot_directory = pathlib.Path(f'../../out_data/{protocol}/plots/{date}{n}')
if not plot_directory.exists():
    plot_directory.mkdir(parents=True)



categorized_PA_epochs = {
    'pa4_ba': [],
    'pa5_ba': [],
    'pa6_ba': [],
    'pa4_fa': [],
    'pa5_fa': [],
    'pa6_fa': [],
    'pa4_va': [],
    'pa5_va': [],
    'pa6_va': [],
    'all_ba_pa': [],
    'all_fa_pa': [],
    'all_va_pa': []
}


# Process each participant
for participant_id, components_to_exclude in tqdm(participant_components.items(), desc="Processing Participants", unit="participant"):
    
    ##loading and preprocessing of raw files
    # Load and concatenate raws
    sqd_files = [
        data_dir / f"{participant_id}_trial01.sqd",
        data_dir / f"{participant_id}_trial02.sqd",
        data_dir / f"{participant_id}_trial03.sqd"
    ]
    raws = [mne.io.read_raw_kit(file, preload=True) for file in sqd_files]
    
       # set dead channel, replaced by fixing 56 coordinates
    #for raw in raws:
    #    raw.info['bads'].extend(dead_channel)

    raw = mne.concatenate_raws(raws)
    
    #repair channel 56
    channel_to_adjust = 'MEG 056'
    #update the position of the channel
    idx_to_adjust = raw.ch_names.index(channel_to_adjust)
    raw.info['chs'][idx_to_adjust]['loc'][:12] = np.array([
                0.09603   , -0.07437   ,  0.00905   , -0.5447052 , -0.83848277,
                0.01558496,  0.        , -0.01858388, -0.9998273 ,  0.8386276 ,
               -0.54461113,  0.01012274])

    if plot_raw:
            raw.plot(n_channels=30, block=True, title=f'MEG Data {participant_id}')

    # find events
    events = mne.find_events(raw)
    mapping = {4: 'ba', 8: 'pa', 16: 'fa', 32: 'va'} 
    
    if debugging: 
        # print number of events and their mapping
        print("Number of events per condition:")
        for code, condition in mapping.items():
            num_events = len(events[events[:, 2] == code])
            print(f"{condition}: {num_events} events")
            
        print("Original event onsets in raw data (seconds):")
        for event in events[:55]:  # Only take the first 25 events
            print(f"Event ID: {event[2]}, Onset: {event[0] / raw.info['sfreq']:.3f} s")

    # create a raw_meg object which excludes all non-meg channels and the dead channel
    raw_meg = raw.copy().pick('meg', exclude='bads')# 
    raw_meg.info['bads'].extend(bad_channels)
    raw_meg.info['bads'].extend(idiosyncratic_bads.get(participant_id, []))  # add participant-specific bad channels
    print(f"Bad channels for participant {participant_id}: {raw_meg.info['bads']}")
    if plot_raw:
        raw.plot_sensors()
        
    # filter the raw data
    raw_filtered = raw_meg.copy().filter(l_freq=l_freq, h_freq=h_freq) 
    if plot_raw: 
        raw_filtered.plot(n_channels=30, block=True, title=f'MEG Data {participant_id}')

    
    ##event mangement
    # time shift events
    # filter for events, this makes four categories of events. you need this to shift times correctly
    ba_events = events[events[:, 2] == 4]
    pa_events = events[events[:, 2] == 8]
    fa_events = events[events[:, 2] == 16]
    va_events = events[events[:, 2] == 32]
    
    #set time shift parameters
    bashift, pashift, fashift, vashift = calculate_shifts(onset_type)

    # shift the event times
    ba_shifted = mne.event.shift_time_events(ba_events, ids=[4], tshift=bashift, sfreq=raw_filtered.info['sfreq'])
    pa_shifted = mne.event.shift_time_events(pa_events, ids=[8], tshift=pashift, sfreq=raw_filtered.info['sfreq'])
    fa_shifted = mne.event.shift_time_events(fa_events, ids=[16], tshift=fashift, sfreq=raw_filtered.info['sfreq'])
    va_shifted = mne.event.shift_time_events(va_events, ids=[32], tshift=vashift, sfreq=raw_filtered.info['sfreq'])

    ##sort shifted events
    # combine all shifted events into one array (this is important, the events need to be chronological for the categorization to make sense
    combined_shifted_events = np.concatenate((ba_shifted, pa_shifted, fa_shifted, va_shifted))
    #sort them chronologically 
    combined_shifted_events = combined_shifted_events[np.argsort(combined_shifted_events[:, 0])]

    ##begin event sorting
    # initialize dictionaries to hold categorized events based on number of events
    event_sequences_4_events = {
        'ba_4_sequence': [],
        'fa_4_sequence': [],
        'va_4_sequence': []
    }
    event_sequences_5_events = {
        'ba_5_sequence': [],
        'fa_5_sequence': [],
        'va_5_sequence': []
    }
    event_sequences_6_events = {
        'ba_6_sequence': [],
        'fa_6_sequence': [],
        'va_6_sequence': []
    }
    
    # keep track of seen PA events and sequences followed by PA
    seen_pa_events = set()
    deviant_pa_sequences = {
        'pa_after_ba': 0,
        'pa_after_fa': 0,
        'pa_after_va': 0
    }

        # Event extraction function
    def extract_sequences(event_type_value):
        i = 0
        while i < len(combined_shifted_events):
            if debugging: 
                print(f"Checking event {i}: {combined_shifted_events[i]}")  # Print current event
            # Capture the event type at index i
            current_event_type = combined_shifted_events[i, 2]
            sequence = [combined_shifted_events[i].tolist()]  # Start the sequence with the current event
            j = i + 1
            # Continue adding events to the sequence while their type is the same as the current_event_type
            while j < len(combined_shifted_events) and combined_shifted_events[j, 2] != event_type_value:
                if combined_shifted_events[j, 2] == current_event_type:
                    sequence.append(combined_shifted_events[j].tolist())  # Add events of the same type to the sequence
                j += 1
            # When event_type_value is found, append it to the sequence and stop
            if j < len(combined_shifted_events) and combined_shifted_events[j, 2] == event_type_value:
                sequence.append(combined_shifted_events[j].tolist())  # Add the event_type_value event
                j += 1
            if debugging:
                # Print the sequence directly after it has been populated
                print(f"Extracted sequence (stopped at event type {event_type_value}):")
                for event in sequence:
                    print(f"Event: {event[2]}, Time: {event[0]}")
            # Move i to the point after the event_type_value event
            i = j
            
            num_events = len(sequence)
            if debugging:
                print(f"number of events: {num_events}")
            
            # Determine which sequence set to send the sequence to based on the number of events
            first_event_id = sequence[0][2]  # Get the ID of the first event
            if debugging: 
                print(f"first event: {first_event_id}")
            target_sequence_set = None  # Initialize target_sequence_set
            if num_events == 5:
                if first_event_id == 4:
                    target_sequence_set = 'ba_4_sequence'
                    event_sequences_4_events[target_sequence_set].append(sequence)
                elif first_event_id == 16:
                    target_sequence_set = 'fa_4_sequence'
                    event_sequences_4_events[target_sequence_set].append(sequence)
                elif first_event_id == 32:
                    target_sequence_set = 'va_4_sequence'
                    event_sequences_4_events[target_sequence_set].append(sequence)
            elif num_events == 6:
                if first_event_id == 4:
                    target_sequence_set = 'ba_5_sequence'
                    event_sequences_5_events[target_sequence_set].append(sequence)
                elif first_event_id == 16:
                    target_sequence_set = 'fa_5_sequence'
                    event_sequences_5_events[target_sequence_set].append(sequence)
                elif first_event_id == 32:
                    target_sequence_set = 'va_5_sequence'
                    event_sequences_5_events[target_sequence_set].append(sequence)
            elif num_events == 7:
                if first_event_id == 4:
                    target_sequence_set = 'ba_6_sequence'
                    event_sequences_6_events[target_sequence_set].append(sequence)
                elif first_event_id == 16:
                    target_sequence_set = 'fa_6_sequence'
                    event_sequences_6_events[target_sequence_set].append(sequence)
                elif first_event_id == 32:
                    target_sequence_set = 'va_6_sequence'
                    event_sequences_6_events[target_sequence_set].append(sequence)

            if debugging:
                # Print which sequence set this sequence was added to
                if target_sequence_set:
                    print(f"Sequence added to: {target_sequence_set}")
               

            # Move index past the current sequence to avoid re-processing
            i = j
            
            # Check if the PA event follows this sequence
            if j < len(combined_shifted_events) and combined_shifted_events[j, 2] == 8:  # Assuming '8' is PA
                sequence.append(combined_shifted_events[j].tolist())  # Add PA event to the sequence
                pa_event = tuple(combined_shifted_events[j].tolist())  # Access the shifted event
                if debugging:
                    # Print details of the PA event
                    print(f"PA Event: {combined_shifted_events[j, 2]}, Time: {combined_shifted_events[j, 0]}, ID: {combined_shifted_events[j, 1]}")
                
                if pa_event not in seen_pa_events:
                    seen_pa_events.add(pa_event)
                    if event_type_value == 4:
                        deviant_pa_sequences['pa_after_ba'] += 1
                    elif event_type_value == 16:
                        deviant_pa_sequences['pa_after_fa'] += 1
                    elif event_type_value == 32:
                        deviant_pa_sequences['pa_after_va'] += 1
        
        else:
            i += 1  # This else should align with the first if statement
    
    # Call the function with your desired event type value
    event_type_value = 8  
    extract_sequences(event_type_value)

    if debugging:
        # Print the number of sequences in each category
        print("Number of sequences in each category:")
        print(f"ba_4_sequence: {len(event_sequences_4_events['ba_4_sequence'])}")
        print(f"ba_5_sequence: {len(event_sequences_5_events['ba_5_sequence'])}")
        print(f"ba_6_sequence: {len(event_sequences_6_events['ba_6_sequence'])}")
        print(f"fa_4_sequence: {len(event_sequences_4_events['fa_4_sequence'])}")
        print(f"fa_5_sequence: {len(event_sequences_5_events['fa_5_sequence'])}")
        print(f"fa_6_sequence: {len(event_sequences_6_events['fa_6_sequence'])}")
        print(f"va_4_sequence: {len(event_sequences_4_events['va_4_sequence'])}")
        print(f"va_5_sequence: {len(event_sequences_5_events['va_5_sequence'])}")
        print(f"va_6_sequence: {len(event_sequences_6_events['va_6_sequence'])}")
    
        print("events in ba_5_sequence:")
        for sequence in event_sequences_5_events['ba_5_sequence']:
            for event in sequence:
                event_time = event[0]  # Assuming the first column contains event time
                event_id = event[2]    # Assuming the third column contains event ID
                print(f"Time: {event_time}, Event ID: {event_id}")

    ##event categorization
    # Initialize dictionary to hold categorized PA events
    categorized_events = {
        'pa_after_ba_4': [],
        'pa_after_ba_5': [],
        'pa_after_ba_6': [],
        'pa_after_fa_4': [],
        'pa_after_fa_5': [],
        'pa_after_fa_6': [],
        'pa_after_va_4': [],
        'pa_after_va_5': [],
        'pa_after_va_6': [],
        'all_ba_events': [],
        'all_fa_events': [],
        'all_va_events': [] 
    }

    # iterate through sequences with 4 events
    for event_type, sequences in event_sequences_4_events.items():
        for sequence in sequences:
            pa_event = sequence[-1]  
            if 'ba_4_sequence' in event_type:
                categorized_events['pa_after_ba_4'].append(pa_event)
                categorized_events['all_ba_events'].append(pa_event)
            elif 'fa_4_sequence' in event_type:
                categorized_events['pa_after_fa_4'].append(pa_event)
                categorized_events['all_fa_events'].append(pa_event)
            elif 'va_4_sequence' in event_type:
                categorized_events['pa_after_va_4'].append(pa_event)
                categorized_events['all_va_events'].append(pa_event)
    # iterate through sequences with 5 events
    for event_type, sequences in event_sequences_5_events.items():
        for sequence in sequences:
            pa_event = sequence[-1]  
            if 'ba_5_sequence' in event_type:
                categorized_events['pa_after_ba_5'].append(pa_event)
                categorized_events['all_ba_events'].append(pa_event)
            elif 'fa_5_sequence' in event_type:
                categorized_events['pa_after_fa_5'].append(pa_event)
                categorized_events['all_fa_events'].append(pa_event)
            elif 'va_5_sequence' in event_type:
                categorized_events['pa_after_va_5'].append(pa_event)
                categorized_events['all_va_events'].append(pa_event)
    # iterate through sequences with 6 events
    for event_type, sequences in event_sequences_6_events.items():
        for sequence in sequences:
            pa_event = sequence[-1]  
            if 'ba_6_sequence' in event_type:
                categorized_events['pa_after_ba_6'].append(pa_event)
                categorized_events['all_ba_events'].append(pa_event)
            elif 'fa_6_sequence' in event_type:
                categorized_events['pa_after_fa_6'].append(pa_event)
                categorized_events['all_fa_events'].append(pa_event)
            elif 'va_6_sequence' in event_type:
                categorized_events['pa_after_va_6'].append(pa_event)
                categorized_events['all_va_events'].append(pa_event)
    if debugging:
        print("Number of events for each category:")
        for category, events in categorized_events.items():
            print(f"{category}: {len(events)}")
        for category, events in categorized_events.items():    
            print(f"Category: {category}")
            for event in events:
                event_time = event[0]  # Assuming the first column is the time
                event_id = event[2]    # Assuming the third column is the event ID
                print(f"  Time: {event_time}, Event ID: {event_id}")
            print()  # Print a new line for better readability

    ##event processing
    #turn events to numpy array, needed for epoching
    pa_after_ba_4 = np.array(categorized_events['pa_after_ba_4'])
    pa_after_ba_5 = np.array(categorized_events['pa_after_ba_5'])
    pa_after_ba_6 = np.array(categorized_events['pa_after_ba_6'])
    pa_after_fa_4 = np.array(categorized_events['pa_after_fa_4'])
    pa_after_fa_5 = np.array(categorized_events['pa_after_fa_5'])
    pa_after_fa_6 = np.array(categorized_events['pa_after_fa_6'])
    pa_after_va_4 = np.array(categorized_events['pa_after_va_4'])
    pa_after_va_5 = np.array(categorized_events['pa_after_va_5'])
    pa_after_va_6 = np.array(categorized_events['pa_after_va_6'])
    all_ba_events = np.array(categorized_events['all_ba_events'])
    all_fa_events = np.array(categorized_events['all_fa_events'])
    all_va_events = np.array(categorized_events['all_va_events'])

    #sort events sets of all events chronologically
    all_ba_events = all_ba_events[all_ba_events[:, 0].argsort()]
    all_fa_events = all_fa_events[all_fa_events[:, 0].argsort()]
    all_va_events = all_va_events[all_va_events[:, 0].argsort()]
    
    ##bad channel handling 
    if interpolate_bads: 
        # interpolate bad channels
        raw_filtered.interpolate_bads(origin=(0.0, 0.0, 0.0), method=dict(meg="MNE"))
        
    # plot the raw filtered data to see effect of interpolation
    if plot_raw: 
        raw_filtered.plot(n_channels=30, block=True, title=f'Filtered MEG Data {participant_id}')

    ## ICA
    if ICA:
        # ICA Configuration
        ica = mne.preprocessing.ICA(n_components=ICA_variance, 
                                    method='picard',
                                    fit_params=dict(ortho=False, extended=False),
                                    random_state=13)
        # fit ICA on filtered data
        ica.fit(raw_filtered)
        # then tries to find the ecg artifacts in ica
        ecg_epochs = mne.preprocessing.create_ecg_epochs(raw_filtered,
                                                         reject=None,
                                                         baseline=(None, 0),
                                                         tmin=-0.5,
                                                         tmax=0.5)
        ecg_evoked = ecg_epochs.average()
        ecg_inds, ecg_scores = ica.find_bads_ecg(
            ecg_epochs, method='ctps')
        raw_filtered.load_data()
        ica.exclude = components_to_exclude
        if display_ica_plots:
            ica.plot_sources(raw, show_scrollbars=False, title=participant_id)
            ica.plot_components(title=participant_id)
            ica.plot_scores(ecg_scores, title=participant_id)
            ica.plot_sources(ecg_evoked, title=participant_id)
            ica.plot_overlay(ecg_evoked, title=participant_id)
        print(f"Components excluded: {ica.exclude}") 
        # apply ICA to raw data
        raw_filtered = ica.apply(raw_filtered)

    ##epoching
    if reject_bad_epochs:
        epochs_pa_after_ba_4 = mne.Epochs(raw_filtered, pa_after_ba_4, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_ba_5 = mne.Epochs(raw_filtered, pa_after_ba_5, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_ba_6 = mne.Epochs(raw_filtered, pa_after_ba_6, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_fa_4 = mne.Epochs(raw_filtered, pa_after_fa_4, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_fa_5 = mne.Epochs(raw_filtered, pa_after_fa_5, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_fa_6 = mne.Epochs(raw_filtered, pa_after_fa_6, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_va_4 = mne.Epochs(raw_filtered, pa_after_va_4, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_va_5 = mne.Epochs(raw_filtered, pa_after_va_5, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_pa_after_va_6 = mne.Epochs(raw_filtered, pa_after_va_6, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_all_ba_events = mne.Epochs(raw_filtered, all_ba_events, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_all_fa_events = mne.Epochs(raw_filtered, all_fa_events, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
        epochs_all_va_events = mne.Epochs(raw_filtered, all_va_events, tmin=tmin, tmax=tmax, reject=reject_criteria, flat=flat_criteria, baseline=baseline, preload=True)
    else:
        epochs_pa_after_ba_4 = mne.Epochs(raw_filtered, pa_after_ba_4, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_ba_5 = mne.Epochs(raw_filtered, pa_after_ba_5, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_ba_6 = mne.Epochs(raw_filtered, pa_after_ba_6, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_fa_4 = mne.Epochs(raw_filtered, pa_after_fa_4, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_fa_5 = mne.Epochs(raw_filtered, pa_after_fa_5, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_fa_6 = mne.Epochs(raw_filtered, pa_after_fa_6, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_va_4 = mne.Epochs(raw_filtered, pa_after_va_4, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_va_5 = mne.Epochs(raw_filtered, pa_after_va_5, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa_after_va_6 = mne.Epochs(raw_filtered, pa_after_va_6, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_all_ba_events = mne.Epochs(raw_filtered, all_ba_events, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_all_fa_events = mne.Epochs(raw_filtered, all_fa_events, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_all_va_events = mne.Epochs(raw_filtered, all_va_events, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)


    # Resample epochs 
    if resample_evoked:
        desired_sfreq = resample_rate
        epochs_list = [
            epochs_pa_after_ba_4, epochs_pa_after_ba_5, epochs_pa_after_ba_6,
            epochs_pa_after_fa_4, epochs_pa_after_fa_5, epochs_pa_after_fa_6,
            epochs_pa_after_va_4, epochs_pa_after_va_5, epochs_pa_after_va_6,
            epochs_all_ba_events, epochs_all_fa_events, epochs_all_va_events
        ]
        for epochs in epochs_list:
            epochs.resample(sfreq=desired_sfreq)

    if dropped_epoch_logging: 
        for idx, epochs in enumerate(epochs_list, start=1):
            print(f"Drop log for epochs set {idx}:")
            print(epochs.drop_log)  # Print the drop log
            epochs.plot_drop_log()  # Plot the drop log

    # store all epochs as we run through the script, so that they can be averaged when all data-sets have been analyzed
    categorized_PA_epochs['pa4_ba'].append(epochs_pa_after_ba_4)
    categorized_PA_epochs['pa5_ba'].append(epochs_pa_after_ba_5)
    categorized_PA_epochs['pa6_ba'].append(epochs_pa_after_ba_6)
    categorized_PA_epochs['pa4_fa'].append(epochs_pa_after_fa_4)
    categorized_PA_epochs['pa5_fa'].append(epochs_pa_after_fa_5)
    categorized_PA_epochs['pa6_fa'].append(epochs_pa_after_fa_6)
    categorized_PA_epochs['pa4_va'].append(epochs_pa_after_va_4)
    categorized_PA_epochs['pa5_va'].append(epochs_pa_after_va_5)
    categorized_PA_epochs['pa6_va'].append(epochs_pa_after_va_6)
    categorized_PA_epochs['all_ba_pa'].append(epochs_all_ba_events)
    categorized_PA_epochs['all_fa_pa'].append(epochs_all_fa_events)
    categorized_PA_epochs['all_va_pa'].append(epochs_all_va_events)
    
    #current state of all epochs after each participant
    print(f"Current state of all epochs across participants:")
    for condition, epochs_list in categorized_PA_epochs.items():
        print(f"Condition: {condition}, Total epochs: {sum([len(e) for e in epochs_list])}")

    ##save epochs data
    epochs_data = {"ba_4": epochs_pa_after_ba_4, 
                   "ba_5": epochs_pa_after_ba_5, 
                   "ba_6": epochs_pa_after_ba_6, 
                   "fa_4": epochs_pa_after_fa_4, 
                   "fa_5": epochs_pa_after_fa_5, 
                   "fa_6": epochs_pa_after_fa_6, 
                   "va_4": epochs_pa_after_va_4, 
                   "va_5": epochs_pa_after_va_5, 
                   "va_6": epochs_pa_after_va_6,
                   "all_ba_pa": epochs_all_ba_events,
                   "all_fa_pa": epochs_all_fa_events,
                   "all_va_pa": epochs_all_va_events}
    if debugging: 
        # Print the number of epochs for each event type
        print("Number of epochs for each type:")
        for event_type, epoch_data in epochs_data.items():
            if epoch_data is not None:
                print(f"{event_type}: {len(epoch_data)} epochs")  # or use epoch_data.n_epochs
            else:
                print(f"{event_type}: No data available.")

    
    # Save the epochs, get evokeds, save them
    evoked_data = {}
    for event_type, epoch_data in epochs_data.items():
        if epoch_data is not None:
            epoch_data.save(output_dir / f'{participant_id}_{onset_type}_epochs_{event_type}-epo.fif', overwrite=True)
            print(f"Saved epochs for {event_type}.") 
            evoked_data[event_type] = epoch_data.average() 
    
    
    # Print the number of epochs for each averaged evoked response
    for key, evoked in evoked_data.items():
        print(f"Averaged {key}: {evoked.nave} epochs")
        # Save the evoked objects to .fif files
        evoked.save(output_dir / f'{participant_id}_{onset_type}_evoked_{key}-ave.fif', overwrite=True)
    
    
    ##plot individual data-set evoked responses
    # Create individual_evks_6 containing only non-zero evoked responses
    individual_evks_6 = {}
    individual_evks_6['ba_6'] = evoked_data['ba_6']
    individual_evks_6['fa_6'] = evoked_data['fa_6']
    individual_evks_6['va_6'] = evoked_data['va_6']

     # create color_dict and linestyle_dict specifically for individual_evks_6
    color_dict_6 = {
        'ba_6': 'blue',
        'fa_6': 'green',
        'va_6': 'red'
    }

    linestyle_dict_6 = {
        'ba_6': '-',
        'fa_6': '-',
        'va_6': '-'
    }
    fig = mne.viz.plot_compare_evokeds(individual_evks_6,
                                       ci=True,
                                       legend='upper left',
                                       show_sensors='upper right',
                                       colors=color_dict_6,
                                       linestyles=linestyle_dict_6,
                                       title=f'{participant_id} Onset: {onset_type} {ICA_file}',
                                       show=False
                                       )
    plt.savefig(f'{plot_directory}/ERPs_3_deviants_{onset_type}_{participant_id}_{ICA_file}.pdf')
    plt.close()
    
    del raw, raws, raw_filtered
    del categorized_events, epochs_data, evoked_data
    
