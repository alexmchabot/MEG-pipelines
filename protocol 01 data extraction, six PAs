#data extraction script protocol one only pa events, this gives you the suppression effect for sequences 
#plots the events and saves the plot
#works as intended as of 10/14/2024

import os
import pathlib
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import mne

# define protocol and onset type
protocol = 'protocol01'
onset_type = 'consonant'          # 'vowel' or 'consonant' depending on where 0 for the trigger is
date = 'October 14'   
n = 'n=14'
trigger_position = 0.000        # change this value to shift away from onset
ICA = True                      # if False, skips ICA
ICA_variance = 40              # either percent e.g. .95 or number of components e.g., 40
display_ica_plots = True      #allows for ICA componants to be viewed, if set to false ICA will just run according to predetermiend component selection
reject_bad_epochs = True
plot_show = False                                              # Change to True to display plots interactively
# define the parameters for bad epochs
reject_criteria = dict(mag=5000e-15) 
flat_criteria = dict(mag=1e-18) 

# define file names for saving based on ICA variable
ICA_file = "_ICA" if ICA else ""

# list of participant IDs
participant_ids = ['R2830', 
                   'R2890', 
                   'R2896', 
                   'R2897', 
                   'R2900',  
                   'R2906', 
                   'R2915', 
                   'R2968', 
                   'R2976', 
                   'R2996', 
                   'R2997', 
                   'R3005', 
                   'R3007', 
                   'R3008'  
                  ]

# mark bad channels
bad_channels = ['MEG 056', 'MEG 086', 'MEG 158', 'MEG 159', 'MEG 160']

# Define participant IDs and their corresponding components to exclude
participant_components = {
    'R2830': [0, 1, 2, 3, 4, 5, 6, 9, 19, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39],
    'R2890': [0, 1, 2, 3, 6, 15, 16, 30, 36, 34, 35, 37, 38, 39, 33, 31, 32],
    'R2896': [0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 15, 16, 20, 22, 25, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #26, 23
    'R2897': [0, 1, 2, 3, 4, 5, 6, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
    'R2900': [0, 1, 2, 3, 11, 26, 37, 35, 34, 36, 38, 39], 
    'R2906': [0, 1, 2, 3, 4, 5, 7, 29, 31, 33, 34, 35, 36, 37, 38, 39],
    'R2915': [0, 1, 2, 3, 5, 9, 12, 13, 14, 25, 26, 28, 30, 32, 36, 37, 38, 39],
    'R2968': [0, 1, 2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #reject 
    'R2976': [0, 1, 2, 3, 10, 26, 29, 32, 33, 34, 35, 36, 38, 37, 39],
    'R2996': [0, 1, 2, 3, 4, 6, 8, 33, 32, 34, 35, 36, 37, 38, 39],
    'R2997': [0, 1, 2, 3, 4, 5, 7, 11, 14, 15, 21, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #what is this massive spike at @ 200? upper left?
    'R3005': [0, 1, 2, 3, 4, 5, 6, 8, 7, 27, 30, 33, 34, 35, 36, 37, 38, 39],
    'R3007': [0, 1, 2, 3, 4, 8, 9, 18, 32, 33, 34, 35, 36, 38, 39, 37], #reject
    'R3008': [0, 1, 2, 3, 4, 5, 6, 12, 14, 15, 16, 20, 22, 31, 32, 33, 34, 35, 36, 37, 38, 39], #far upper right blob
}


# define the parameters for the filter
l_freq = 1
h_freq = 25

# define the time limits for the epochs
tmin = -0.1
tmax = 0.8

# define the parameters for bad epochs
reject_criteria = dict(mag=5000e-15) 
flat_criteria = dict(mag=1e-17)  # 1 fT

# define subdirectory based on onset type
subdirectory = "V_onset" if onset_type == 'vowel' else "C_onset"

# load data directory
data_dir = pathlib.Path(f'../../all data/{protocol}')

# ensure the output directory exists
output_dir = pathlib.Path(f'../../out_data/{protocol}/{subdirectory}')
output_dir.mkdir(parents=True, exist_ok=True)

# only modify below here for a permanent reason!
# define trigger shifts based on onset type
def calculate_shifts(onset_type):
    if onset_type == 'vowel':
        bashift = 0.190-trigger_position
        pashift = 0.125-trigger_position
        fashift = 0.185-trigger_position
        vashift = 0.215-trigger_position
    elif onset_type == 'consonant':
        bashift = 0.160-trigger_position
        pashift = 0.060-trigger_position
        fashift = 0.100-trigger_position
        vashift = 0.160-trigger_position
    else:
        raise ValueError("Unknown onset_type. Supported values are 'vowel' or 'consonant'.")
    return bashift, pashift, fashift, vashift

# define event conditions 
conditions = ['pa1', 'pa2', 'pa3', 'pa4', 'pa5', 'pa6']  

# Initialize lists to store events for each PA occurrence
all_pa_epochs = {
    'pa1': [],
    'pa2': [],
    'pa3': [],
    'pa4': [],
    'pa5': [],
    'pa6': []
}

# iterate over each participant data-set
for participant_id, components_to_exclude in tqdm(participant_components.items(), desc="Processing Participants", unit="participant"):
    # Load and concatenate raws
    sqd_files = [
        data_dir / f"{participant_id}_trial01.sqd",
        data_dir / f"{participant_id}_trial02.sqd",
        data_dir / f"{participant_id}_trial03.sqd"
    ]
    raws = [mne.io.read_raw_kit(file, preload=True) for file in sqd_files]
    raw = mne.concatenate_raws(raws)

    # Ensure the sampling frequency is 250 Hz
    desired_sfreq = 250
    if raw.info['sfreq'] != desired_sfreq:
        print(f"Downsampling the data from {raw.info['sfreq']} Hz to {desired_sfreq} Hz.")
        raw = raw.resample(sfreq=desired_sfreq)  # Resample the raw object

    # Set bad channels
    raw.info['bads'] = bad_channels
        
     # find events
    events = mne.find_events(raw)
    mapping = {4: 'ba', 8: 'pa', 16: 'fa', 32: 'va'}
    
    # filter for events, this makes four categories of events. you need this to shift times correctly
    ba_events = events[events[:, 2] == 4]
    pa_events = events[events[:, 2] == 8]
    fa_events = events[events[:, 2] == 16]
    va_events = events[events[:, 2] == 32]
    
    # print total number of events to compare to VA events
    print(f"Total number of events for participant {participant_id}: {len(events)}")
    print(f"Number of BA Events for {participant_id}: {ba_events.shape[0]}")
    print(f"Number of PA Events for {participant_id}: {pa_events.shape[0]}")
    print(f"Number of FA Events for {participant_id}: {fa_events.shape[0]}")
    print(f"Number of VA Events for {participant_id}: {va_events.shape[0]}")

    bashift, pashift, fashift, vashift = calculate_shifts(onset_type)
    print(f"BA Shift: {bashift}, PA Shift: {pashift}, FA Shift: {fashift}, VA Shift: {vashift}")

    # shift the event times
    ba_shifted = mne.event.shift_time_events(ba_events, ids=[4], tshift=bashift, sfreq=raw.info['sfreq'])
    pa_shifted = mne.event.shift_time_events(pa_events, ids=[8], tshift=pashift, sfreq=raw.info['sfreq'])
    fa_shifted = mne.event.shift_time_events(fa_events, ids=[16], tshift=fashift, sfreq=raw.info['sfreq'])
    va_shifted = mne.event.shift_time_events(va_events, ids=[32], tshift=vashift, sfreq=raw.info['sfreq'])

    #Combine all shifted events into one array
    combined_shifted_events = np.concatenate((ba_shifted, pa_shifted, fa_shifted, va_shifted))
    #sort them chronologically (this is important, the events need to be chronological for the categorization to make sense
    combined_shifted_events = combined_shifted_events[np.argsort(combined_shifted_events[:, 0])]
    # Print the combined shifted events and their count
    print(f"Combined Shifted Events: {combined_shifted_events}")
    print(f"Number of Combined Shifted Events: {combined_shifted_events.shape[0]}")
    
    # print original PA event times
    print("Original PA event times:")
    for event_id, event_type in mapping.items():
        if event_id == 8:
            events_of_type = events[events[:, 2] == event_id]
            for i in range(min(5, len(events_of_type))):
                event = events_of_type[i]
                print(f"{event_type} event {i+1}: Time {event[0] / raw.info['sfreq']} s")

    # Print shifted PA event times
    print("\nShifted PA event times:")
    shifted_events = pa_shifted  # Assuming pa_shifted contains shifted events
    for event_id, event_type in mapping.items():
        if event_id == 8:
            events_of_type = shifted_events[shifted_events[:, 2] == event_id]
            for i in range(min(5, len(events_of_type))):
                event = events_of_type[i]
                print(f"{event_type} event {i+1}: Time {event[0] / raw.info['sfreq']} s")


    # Create a raw_meg object which excludes all non-meg channels
    raw_meg = raw.pick_types(meg=True, exclude='bads')
    
    # Filter the raw data
    raw_filtered = raw_meg.copy().filter(l_freq=l_freq, h_freq=h_freq)
    
    # conditionally run ICA
    if ICA:
        # ICA Configuration
        n_components = ICA_variance
        method = 'picard'
        max_iter = 1000
        fit_params = dict(fastica_it=5)
        random_state = 13

        ica = mne.preprocessing.ICA(n_components=ICA_variance, 
                                    method=method,
                                    max_iter=max_iter,
                                    fit_params=fit_params,
                                    random_state=random_state)
         # fit ICA on filtered data
        ica.fit(raw_filtered)
         # then tries to find the ecg artifacts in ica
        ecg_epochs = mne.preprocessing.create_ecg_epochs(raw_filtered,
                                                         reject=None,
                                                         baseline=(None, -.02),
                                                         tmin=-0.5,
                                                         tmax=0.5)
        ecg_evoked = ecg_epochs.average()
        ecg_inds, ecg_scores = ica.find_bads_ecg(
            ecg_epochs, method='ctps')

        raw_filtered.load_data()
        ica.exclude = components_to_exclude
        if display_ica_plots:
            ica.plot_sources(raw, show_scrollbars=False)
            ica.plot_components()
            ica.plot_scores(ecg_scores)
            ica.plot_sources(ecg_evoked)
            ica.plot_overlay(ecg_evoked)
        
        print(f"Components excluded: {ica.exclude}") 
        # apply ICA to raw data
        raw_filtered = ica.apply(raw_filtered)

    
    # Initialize lists to store sequences of 'pa' events
    pa_sequences = []
    
    # Iterate over events to extract sequences of 'pa' events
    i = 0
    while i < len(combined_shifted_events):
        if combined_shifted_events[i, 2] == 8:  # Check if current event is 'pa'
            # Start a new sequence
            pa_sequence = [combined_shifted_events[i].tolist()]
    
            # Continue adding events to the sequence while they are consecutive 'pa' events
            j = i + 1
            while j < len(combined_shifted_events) and combined_shifted_events[j, 2] == 8:
                pa_sequence.append(combined_shifted_events[j].tolist())
                j += 1
    
            # Store the sequence (regardless of length for now to debug)
            pa_sequences.append(pa_sequence)
            
            # Move index past the current sequence to avoid re-processing
            i = j
        else:
            i += 1
    
    # Initialize lists to store events for each PA occurrence for the current participant
    pa1_participant = []
    pa2_participant = []
    pa3_participant = []
    pa4_participant = []
    pa5_participant = []
    pa6_participant = []

    # Iterate through sequences and store events in respective lists
    for sequence in pa_sequences:
        for event_idx, event in enumerate(sequence, start=1):
            if event_idx == 1:
                pa1_participant.append(event)
            elif event_idx == 2:
                pa2_participant.append(event)
            elif event_idx == 3:
                pa3_participant.append(event)
            elif event_idx == 4:
                pa4_participant.append(event)
            elif event_idx == 5:
                pa5_participant.append(event)
            elif event_idx == 6:
                pa6_participant.append(event)
                

# Convert lists to NumPy arrays after collecting events for the current participant
    pa1_participant = np.array(pa1_participant)
    pa2_participant = np.array(pa2_participant)
    pa3_participant = np.array(pa3_participant)
    pa4_participant = np.array(pa4_participant)
    pa5_participant = np.array(pa5_participant)
    pa6_participant = np.array(pa6_participant)


    if reject_bad_epochs:
        epochs_pa1 = mne.Epochs(raw_filtered, 
                               pa1_participant, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)
        epochs_pa2 = mne.Epochs(raw_filtered, 
                               pa2_participant, 
                               tmin=tmin,
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)
        epochs_pa3 = mne.Epochs(raw_filtered, 
                               pa3_participant, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)
        epochs_pa4 = mne.Epochs(raw_filtered, 
                               pa4_participant, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)
        epochs_pa5 = mne.Epochs(raw_filtered, 
                               pa5_participant, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)
        epochs_pa6 = mne.Epochs(raw_filtered, 
                               pa6_participant, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               preload=True)

    
    else:
        epochs_pa1 = mne.Epochs(raw_filtered, pa1_participant, tmin=tmin, tmax=tmax, preload=True)
        epochs_pa2 = mne.Epochs(raw_filtered, pa2_participant, tmin=tmin, tmax=tmax, preload=True)
        epochs_pa3 = mne.Epochs(raw_filtered, pa3_participant, tmin=tmin, tmax=tmax, preload=True)
        epochs_pa4 = mne.Epochs(raw_filtered, pa4_participant, tmin=tmin, tmax=tmax, preload=True)
        epochs_pa5 = mne.Epochs(raw_filtered, pa5_participant, tmin=tmin, tmax=tmax, preload=True)
        epochs_pa6 = mne.Epochs(raw_filtered, pa6_participant, tmin=tmin, tmax=tmax, preload=True)

    print(f"Participant {participant_id}:")
    print(f"Number of epochs for pa1: {len(epochs_pa1)}")
    print(f"Number of epochs for pa2: {len(epochs_pa2)}")
    print(f"Number of epochs for pa3: {len(epochs_pa3)}")
    print(f"Number of epochs for pa4: {len(epochs_pa4)}")
    print(f"Number of epochs for pa5: {len(epochs_pa5)}")
    print(f"Number of epochs for pa6: {len(epochs_pa6)}")

        # Append epochs to the accumulated dataset
    all_pa_epochs['pa1'].append(epochs_pa1)
    all_pa_epochs['pa2'].append(epochs_pa2)
    all_pa_epochs['pa3'].append(epochs_pa3)
    all_pa_epochs['pa4'].append(epochs_pa4)
    all_pa_epochs['pa5'].append(epochs_pa5)
    all_pa_epochs['pa6'].append(epochs_pa6)
    
    # Clean up variables
    del raw, raws, raw_filtered, raw_meg

    # Print current state of all_pa_epochs after each participant
    print(f"Current state of all_pa_epochs:")
    for condition, epochs_list in all_pa_epochs.items():
        print(f"Condition: {condition}, Number of participants: {len(epochs_list)}, Total epochs: {sum([len(e) for e in epochs_list])}")

# After the loop, you can print the final state of all_pa_epochs
print("Final state of all_pa_epochs:")
for condition, epochs_list in all_pa_epochs.items():
    print(f"Condition: {condition}, Number of participants: {len(epochs_list)}, Total epochs: {sum([len(e) for e in epochs_list])}")

# Now all_pa_epochs contains all epochs for pa1 to pa6 across all participants
# Initialize a dictionary to store ERPs for each condition
evks = {}

# Iterate through each condition in all_pa_epochs
for condition, epochs_list in all_pa_epochs.items():
    # Combine all epochs across participants for the current condition
    combined_epochs = mne.concatenate_epochs(epochs_list)
    
    # Calculate the ERP (average across epochs)
    evk = combined_epochs.average()
    
    # Store the ERP in the dictionary
    evks[condition] = evk

plot_directory = pathlib.Path(f'../../out_data/{protocol}/plots/{date}{n}')
if not plot_directory.exists():
    plot_directory.mkdir(parents=True)

# define file names for saving based on ICA variable
ICA_file = "_ICA" if ICA else ""
reject_suffix = "_bad_epochs_rejected" if reject_bad_epochs else ""


# Calculate the number of participants based on the evoked objects
num_participants_used = len(epochs_list)

# Adjust the title with the correct number of participants
title = f'{protocol} participants ({num_participants_used}), {onset_type} onset {ICA_file} {ICA_file} {reject_suffix}'

# Define info for the plots
color_dict = {'pa1': 'red', 'pa2': 'orange', 'pa3': 'yellow', 'pa4': 'green', 'pa5': 'blue', 'pa6': 'indigo'}
linestyle_dict = {'pa1': '-', 'pa2': '-', 'pa3': '-', 'pa4': '-', 'pa5': '-', 'pa6': '-'}

#all channels for all participants
fig = mne.viz.plot_compare_evokeds(evks,
                             ci=False,
                             legend='upper left',
                             show_sensors='upper right',
                             colors=color_dict,
                             linestyles=linestyle_dict,
                             title=f'Suppression effect of PA condition sequencees; participants ({n}), {onset_type} onset{ICA_file} {reject_file}',
                             show=plot_show,    
                             #ylim=dict(mag=[0, 30])# set y-axis limits
                                  ) 
plt.savefig(f'{plot_directory}/ERPs_6_pa_conditions{onset_type}{ICA_file}{reject_suffix}.pdf')

#all channels for all participants
fig = mne.viz.plot_compare_evokeds(evks,
                             combine='mean',   
                             ci=False,
                             legend='upper left',
                             show_sensors='upper right',
                             colors=color_dict,
                             linestyles=linestyle_dict,
                             title=f'Suppression effect of PA condition sequencees; participants ({n}), {onset_type} onset{ICA_file} {reject_file}',
                             show=True
                                  ) 

# Create subplots for the butterfly plots
fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))  # Adjusted to fit 3x2 grid

# Access each evoked object from the dictionary using its key
evks['pa1'].plot(exclude='bads', spatial_colors=True, axes=axes[0, 0], show=False)
axes[0, 0].set_title('PA1, all channels')

evks['pa2'].plot(exclude='bads', spatial_colors=True, axes=axes[0, 1], show=False)
axes[0, 1].set_title('PA2, all channels')

evks['pa3'].plot(exclude='bads', spatial_colors=True, axes=axes[1, 0], show=False)
axes[1, 0].set_title('PA3, all channels')

evks['pa4'].plot(exclude='bads', spatial_colors=True, axes=axes[1, 1], show=False)
axes[1, 1].set_title('PA4, all channels')

evks['pa5'].plot(exclude='bads', spatial_colors=True, axes=axes[2, 0], show=False)
axes[2, 0].set_title('PA5, all channels')

evks['pa6'].plot(exclude='bads', spatial_colors=True, axes=axes[2, 1], show=False)
axes[2, 1].set_title('PA6, all channels')

# Calculate the maximum ylim value among the six plots
max_ylim = max([ax.get_ylim()[1] for ax in axes.flatten()])

# Set the same ylim value for all subplots
for ax in axes.flatten():
    ax.set_ylim([-max_ylim, max_ylim])

# Add a title to the entire plot
plt.suptitle(f'Suppression effect of PA condition sequencees; participants ({n}), {onset_type} onset{ICA_file} {reject_file}', fontsize=14)

# Display the plot
plt.show()


#create a 3x6 grid of subplots
fig, axs = plt.subplots(6, 6, figsize=(20, 12), gridspec_kw={'height_ratios': [1, 1, 1, 1, 1, 1], 'hspace': 0})

times = [0.150, 0.200, 0.250, 0.300, 0.350, 0.400]

#plot the second topographic map on the middle subplot
evks['pa1'].plot_topomap(times=times, ch_type='mag', axes=axs[0, :], show=False, colorbar=False)

#plot the third topographic map on the bottom subplot
evks['pa2'].plot_topomap(times=times, ch_type='mag', axes=axs[1, :], show=False, colorbar=False)

#plot the third topographic map on the bottom subplot
evks['pa3'].plot_topomap(times=times, ch_type='mag', axes=axs[2, :], show=False, colorbar=False)

#plot the third topographic map on the bottom subplot
evks['pa4'].plot_topomap(times=times, ch_type='mag', axes=axs[3, :], show=False, colorbar=False)

#plot the third topographic map on the bottom subplot
evks['pa5'].plot_topomap(times=times, ch_type='mag', axes=axs[4, :], show=False, colorbar=False)

#plot the third topographic map on the bottom subplot
evks['pa6'].plot_topomap(times=times, ch_type='mag', axes=axs[5, :], show=False, colorbar=False)
plt.show()

# Get the channel names for left hemisphere (based on negative x-coordinate)
left_hemisphere_chs = [ch_name for ch_name, pos in zip(evk.info['ch_names'], evk.info['chs']) if pos['loc'][0] < 0]
#left hemispehere chans
mne.viz.plot_compare_evokeds(evks,
                             combine='gfp',
                             picks = left_hemisphere_chs,
                             ci=False,
                             legend='upper left',
                             show_sensors='upper right',
                             colors=color_dict,
                             linestyles=linestyle_dict,
                             title=f'Suppression effect of PA condition sequencees; participants ({n}), {onset_type} onset{ICA_file} {reject_file}',
                             show=plot_show,
                             ylim=dict(mag=[0, 30])# set y-axis limits
                                      ) 
plt.savefig(f'{plot_directory}/ERPs_6_pa_conditions_left_hemisphere_channels_{onset_type}{ICA_file}{reject_suffix}.pdf')
plt.close()
