import mne
import pathlib
import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols

date = 'October 31'
protocol = 'protocol02'
onset_type = 'consonant' 
ICA = True
reject_bad_epochs = True
debugging = True
dataset = 'V_onset' if onset_type == 'vowel' else 'C_onset'

# Define time intervals (start, end) in seconds
time_intervals = [(0.1, 0.2), (0.2, 0.3), (0.3, 0.4), (0.4, 0.5)]
participants = ['R3027', 'R3039', 'R3401', 'R3703', 'R3078', 
                'R3079', 'R3086', 'R3090', 'R3109', 'R3112', 
                'R3113', 'R3117', 'R3120', 'R3124', 'R3126']

left_temporal_channels = ['MEG 131', 'MEG 088', 'MEG 130', 'MEG 089', 'MEG 137', 
                          'MEG 046', 'MEG 138', 'MEG 080', 'MEG 091', 'MEG 041', 
                          'MEG 078', 'MEG 139']

conditions_6 = ['ba_6', 'fa_6', 'va_6']

# Directories
data_dir = pathlib.Path(r'C:\Users\alexm\OneDrive\Documents\work\post doc project\piloting\MMN data\out_data\protocol02\C_onset')
ICA_suffix = "ICA" if ICA else ""
reject_suffix = "bad_epochs_rejected" if reject_bad_epochs else ""

# Initialize data structure for statistical analysis
data = []

# Load and process the evoked data
for participant in participants:
    for condition in conditions_6:
        file_path = data_dir / f"{participant}_{onset_type}_evoked_{condition}-ave.fif"
        evokeds = mne.read_evokeds(file_path, baseline=None)

        # Pick both left temporal and all channels for analysis
        for evoked in evokeds:
            # Calculate mean amplitude for each time interval for left temporal channels
            evoked_left = evoked.copy().pick_channels(left_temporal_channels)
            for start, end in time_intervals:
                evoked_crop = evoked_left.copy().crop(start, end)
                mean_amplitude = evoked_crop.data.mean(axis=0).mean()  # Mean across channels and time
                data.append({
                    'Participant': participant,
                    'Condition': condition,
                    'MeanAmplitude': mean_amplitude,
                    'ChannelSelection': 'Left Temporal',
                    'TimeInterval': f"{int(start*1000)}-{int(end*1000)} ms"
                })

            # Calculate mean amplitude for each time interval for all channels
            evoked_all = evoked.copy().pick_types(meg=True)  # Assuming this picks all MEG channels
            for start, end in time_intervals:
                evoked_crop = evoked_all.copy().crop(start, end)
                mean_amplitude = evoked_crop.data.mean(axis=0).mean()  # Mean across channels and time
                data.append({
                    'Participant': participant,
                    'Condition': condition,
                    'MeanAmplitude': mean_amplitude,
                    'ChannelSelection': 'All Channels',
                    'TimeInterval': f"{int(start*1000)}-{int(end*1000)} ms"
                })

# Convert collected data into a DataFrame for statistical analysis
df = pd.DataFrame(data)

# Replace condition names for readability
df['Condition'] = df['Condition'].replace({
    'ba_6': 'BA x 6 -> PA',
    'fa_6': 'FA x 6 -> PA',
    'va_6': 'VA x 6 -> PA'
})

# Convert columns to categorical types
df['Condition'] = df['Condition'].astype('category')
df['ChannelSelection'] = df['ChannelSelection'].astype('category')
df['TimeInterval'] = df['TimeInterval'].astype('category')
df['Participant'] = df['Participant'].astype('category')

# Fit a repeated measures ANOVA
# This method assumes a wide format; ensure that Participant is treated as a random effect appropriately.
formula = "MeanAmplitude ~ C(Condition) * C(ChannelSelection) * C(TimeInterval)"
model = ols(formula, data=df).fit()
anova_table = sm.stats.anova_lm(model, typ=2)

print(anova_table)

#important
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Ensure that 'MeanAmplitude' is the response variable and the other factors are in the DataFrame
tukey_results = pairwise_tukeyhsd(endog=df['MeanAmplitude'], groups=df['TimeInterval'], alpha=0.05)
print(tukey_results)

#keep this, important
# Convert categorical columns to string
df['Condition'] = df['Condition'].astype(str)
df['TimeInterval'] = df['TimeInterval'].astype(str)

# Now create the new column for the combined factor
df['Condition_TimeInterval'] = df['Condition'] + " " + df['TimeInterval']
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Perform Tukey's HSD test for the combined factor
tukey_results_combined = pairwise_tukeyhsd(endog=df['MeanAmplitude'], groups=df['Condition_TimeInterval'], alpha=0.05)
print(tukey_results_combined)




# to find ratios


conditions_6 = ['ba_6', 'fa_6', 'va_6']

# Directories
data_dir = pathlib.Path(r'C:\Users\alexm\OneDrive\Documents\work\post doc project\piloting\MMN data\out_data\protocol02\C_onset')
ICA_suffix = "ICA" if ICA else ""
reject_suffix = "bad_epochs_rejected" if reject_bad_epochs else ""

# Initialize data structure for statistical analysis
data = []

# Load and process the evoked data
for participant in participants:
    for condition in conditions_6:
        file_path = data_dir / f"{participant}_{onset_type}_evoked_{condition}-ave.fif"
        evokeds = mne.read_evokeds(file_path, baseline=None)

        # Pick left temporal channels
        for evoked in evokeds:
            evoked_left = evoked.copy().pick_channels(left_temporal_channels)

            # Calculate peak amplitude for the specified time interval
            for start, end in time_intervals:
                evoked_crop = evoked_left.copy().crop(start, end)
                peak_amplitude = evoked_crop.data.max()  # Find the peak amplitude across channels
                data.append({
                    'Participant': participant,
                    'Condition': condition,
                    'PeakAmplitude': peak_amplitude,
                    'ChannelSelection': 'Left Temporal',
                    'TimeInterval': f"{int(start*1000)}-{int(end*1000)} ms"
                })

# Convert collected data into a DataFrame for statistical analysis
df = pd.DataFrame(data)

# Replace condition names for readability
df['Condition'] = df['Condition'].replace({
    'ba_6': 'BA x 6 -> PA',
    'fa_6': 'FA x 6 -> PA',
    'va_6': 'VA x 6 -> PA'
})

# Calculate grand averages for peak amplitudes
grand_averages = df.groupby('Condition')['PeakAmplitude'].mean().reset_index()

# Extract peak amplitudes
ba_peak = grand_averages.loc[grand_averages['Condition'] == 'BA x 6 -> PA', 'PeakAmplitude'].values[0]
fa_peak = grand_averages.loc[grand_averages['Condition'] == 'FA x 6 -> PA', 'PeakAmplitude'].values[0]
va_peak = grand_averages.loc[grand_averages['Condition'] == 'VA x 6 -> PA', 'PeakAmplitude'].values[0]

# Calculate ratios
ratios = {
    'BA_FA': ba_peak / fa_peak,
    'BA_VA': ba_peak / va_peak,
    'FA_VA': fa_peak / va_peak
}

# Display the ratios
print("Ratios of Peak Amplitudes:")
for comparison, ratio in ratios.items():
    print(f"{comparison}: {ratio:.3f}")

# If needed, conduct statistical analysis to determine significance between conditions
formula = "PeakAmplitude ~ C(Condition) * C(ChannelSelection) * C(TimeInterval)"
model = ols(formula, data=df).fit()
anova_table = sm.stats.anova_lm(model, typ=2)

print(anova_table)
