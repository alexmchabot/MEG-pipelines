#this protocol epochs all BA, FA, and VA events. It epochs a single PA event in sequences of PA. It produces thus approximately three times as many PA evoked objects as the other conditions
#works as intended as of 10/17/2024
import pathlib
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import mne


# define protocol and onset type, ICA, epoch rejection, etc
protocol = 'protocol01'
onset_type = 'vowel'         # 'vowel' or 'consonant' depending on where 0 for the trigger is
date = 'October 23'             # marks last time script was ran  
debugging = False
trigger_position = 0.00         # change this value to shift away from onset
plot_raw = False
ICA_on_raw = True                  # run ICA on raw data   OR
ICA_on_epochs = False               #run ICA on epochs
ICA_variance = .97                # either percent e.g. .95 or number of components e.g., 40
display_ica_plots = False        # allows for ICA componants to be viewed, if set to false ICA will just run according to predetermiend component selection
reject_bad_epochs = True
dropped_epoch_logging = False   #shows logs for dropped epochs
interpolate_bads = True
resample_evoked = True
resample_rate = 250
baseline = (None, 0)            # means from the first instant to t = 0
show_individual_plots=False
pa_epoch_to_categorize = 4 #good results with 5

# define the parameters for the filter
l_freq = .1
h_freq = 30

# define the time limits for the epochs
tmin = -0.1
tmax = 0.8  

# define the parameters for bad epochs
reject_criteria = dict(mag=3000e-15) 
flat_criteria = dict(mag=1e-15) 


# list of participant IDs
participant_ids = ['R2830', #clean data, good plot
                   'R2890', #clean data, though there is some high frequency noise here and there good plot
                   'R2896', #really noisy data some flattish channels, almost looks like a filling or something; potential reject,
                   'R2897', #clean data
                   'R2900', #clean data
                   'R2906', #clean data
                   'R2915', #noisy data, there is worse. . . there is something happening on the right side at the top of the ear or just above
                   'R2968', #high frequency noise in all of the ICA components, raw plot has low frequency drift? third reject candidate
                   'R2976', #clean data
                   'R2996', #data is a little noisy, 
                   'R2997', #data is ok
                   'R3005', #data is ok, 
                   'R3007', #data is ok, but there are a surprising amount of flat channels 
                   'R3008'  #weak weak signal, handfull of bad channels, participant with filling, bad channels cluster together, most channels are clean
                  ]
n = 'n=' + str(len(participant_ids))

# bad channels dictionary 
#dead_channel = ['MEG 056'] #this channel has bad coordinates. it is also dead for part 01. if you ever can get the coordinates you can try interpolating it
bad_channels = ['MEG 086'] #86 is always bad, but it can be interpolated


# Define participant IDs and their corresponding components to exclude
participant_components = {
    'R2830': [0, 1, 2, 4, 5, 6, 11, 14, 15, 16], #17 componants 
    'R2890': [0, 1, 2, 3, 4, 5, 10, 14, 23, 25, 26, 27, 28], #29 components 
    'R2896': [0, 1, 2, 3, 4, 5, 7], #8 components
    'R2897': [0, 1, 2, 3, 4, 5, 7, 20, 21, 22, 23, 24, 25], #  20 components
    'R2900': [0, 1, 2, 3, 8, 14, 15, 18, 19, 21, 22, 24, 25], # 26 components 
    'R2906': [0, 1, 2, 3, 4, 5, 6, 9, 11, 13, 15, 16, 19, 18, 20, 21, 22], #23 components 
    'R2915': [0, 1, 2, 3, 7, 8, 14, 16], #17 components 
    'R2968': [0, 1, 2, 3, 4, 12, 13, 14], #25 components    
    'R2976': [0, 1, 2, 3, 9, 11, 14, 15, 19], #20 components
    'R2996': [0, 1, 2, 3, 9, 15, 16, 19, 20, 21], #22 components 7
    'R2997': [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 10], #11 components 
    'R3005': [0, 1, 2, 4, 6, 7, 9, 18, 17], # 20 components 3
    'R3007': [0, 1, 3, 2, 12, 13, 14, 17], # 18 components 
    'R3008': [0, 1, 2, 3, 4, 5, 7], #8 components 
}

idiosyncratic_bads = {
    'R2830': ['MEG 056'], 
    'R2890': [],
    'R2896': ['MEG 001', 'MEG 002', 'MEG 013', 'MEG 014', 'MEG 015', 'MEG 016', 'MEG 017', 'MEG 018', 'MEG 031'], 
    'R2897': [], 
    'R2900': [], 
    'R2906': [], 
    'R2915': [], 
    'R2968': ['MEG 026', 'MEG 054', 'MEG 056', 'MEG 057', 'MEG 144'], 
    'R2976': ['MEG 056'],
    'R2996': ['MEG 046', 'MEG 056'], 
    'R2997': ['MEG 056'], 
    'R3005': ['MEG 056', 'MEG 062', 'MEG 105'], 
    'R3007': ['MEG 004', 'MEG 026', 'MEG 030', 'MEG 039', 'MEG 040', 'MEG 051', 'MEG 056', 'MEG 059', 'MEG 061', 
              'MEG 062', 'MEG 065', 'MEG 067', 'MEG 072', 'MEG 080', 'MEG 088', 'MEG 090', 
              'MEG 096', 'MEG 099', 'MEG 103', 'MEG 104', 'MEG 105', 'MEG 106', 'MEG 111', 
              'MEG 112', 'MEG 113', 'MEG 115', 'MEG 130', 'MEG 132', 'MEG 139', 'MEG 145', 
              'MEG 149', 'MEG 151', 'MEG 152', 'MEG 154', 'MEG 157'], 
    'R3008': [],
}


# Store total counts of epochs across all participants
total_epochs_ba = 0
total_epochs_pa = 0
total_epochs_fa = 0
total_epochs_va = 0

# load data directory
data_dir = pathlib.Path(f'../../all data/{protocol}')
# define subdirectory based on onset type
subdirectory = "V_onset" if onset_type == 'vowel' else "C_onset"
# ensure the output directory exists
output_dir = pathlib.Path(f'../../out_data/{protocol}/{subdirectory}')
output_dir.mkdir(parents=True, exist_ok=True)
# define file names for saving based on processing variables
ICA_suffix = "ICA_raw" if ICA_on_raw else "ICA_epochs" if ICA_on_epochs else ""
reject_suffix = "bad_epochs_rejected" if reject_bad_epochs else ""

#define directory for participant plots
plot_directory = pathlib.Path(f'../../out_data/{protocol}/plots/{date}')
if not plot_directory.exists():
    plot_directory.mkdir(parents=True)



# only modify below here for a permanent reason!
# define trigger shifts based on onset type
def calculate_shifts(onset_type):
    if onset_type == 'vowel':
        bashift = 0.190-trigger_position
        pashift = 0.108-trigger_position
        fashift = 0.183-trigger_position
        vashift = 0.197-trigger_position
    elif onset_type == 'consonant':
        bashift = 0.157-trigger_position
        pashift = 0.033-trigger_position 
        fashift = 0.062-trigger_position 
        vashift = 0.156-trigger_position
    else:
        raise ValueError("Problem, neither 'vowel' nor 'consonant'.")
    return bashift, pashift, fashift, vashift
    
for participant_id, components_to_exclude in tqdm(participant_components.items(), desc="Processing Participants", unit="participant"):

    ##loading and preprocessing of raw files
    # Load and concatenate raws
    sqd_files = [
        data_dir / f"{participant_id}_trial01.sqd",
        data_dir / f"{participant_id}_trial02.sqd",
        data_dir / f"{participant_id}_trial03.sqd"
    ]
    raws = [mne.io.read_raw_kit(file, preload=True) for file in sqd_files]
    
    # set dead channel, replaced by fixing 56 coordinates
    #for raw in raws:
    #    raw.info['bads'].extend(dead_channel)

    raw = mne.concatenate_raws(raws)
    
    #repair channel 56
    channel_to_adjust = 'MEG 056'
    #update the position of the channel
    idx_to_adjust = raw.ch_names.index(channel_to_adjust)
    raw.info['chs'][idx_to_adjust]['loc'][:12] = np.array([
                0.09603   , -0.07437   ,  0.00905   , -0.5447052 , -0.83848277,
                0.01558496,  0.        , -0.01858388, -0.9998273 ,  0.8386276 ,
               -0.54461113,  0.01012274])

    if plot_raw:
            raw.plot(n_channels=30, block=True, title=f'MEG Data {participant_id}')
            
        
    # find events
    events = mne.find_events(raw)
    mapping = {4: 'ba', 8: 'pa', 16: 'fa', 32: 'va'} 
    
    if debugging: 
        # print number of events and their mapping
        print("Number of events per condition:")
        for code, condition in mapping.items():
            num_events = len(events[events[:, 2] == code])
            print(f"{condition}: {num_events} events")
            
        print("Original event onsets in raw data (seconds):")
        for event in events[:55]:  # Only take the first 25 events
            print(f"Event ID: {event[2]}, Onset: {event[0] / raw.info['sfreq']:.3f} s")

    # create a raw_meg object which excludes all non-meg channels and the dead channel
    raw_meg = raw.copy().pick('meg', exclude='bads')# 
    raw_meg.info['bads'].extend(bad_channels)
    raw_meg.info['bads'].extend(idiosyncratic_bads.get(participant_id, []))  # add participant-specific bad channels
    print(f"Bad channels for participant {participant_id}: {raw_meg.info['bads']}")
    if plot_raw:
        raw.plot_sensors()
        
    # filter the raw data
    raw_filtered = raw_meg.copy().filter(l_freq=l_freq, h_freq=h_freq) 
    if plot_raw: 
        raw_filtered.plot(n_channels=30, block=True, title=f'MEG Data {participant_id}')

    ##event mangement
    # time shift events
    # filter for events, this makes four categories of events. you need this to shift times correctly
    ba_events = events[events[:, 2] == 4]
    pa_events = events[events[:, 2] == 8]
    fa_events = events[events[:, 2] == 16]
    va_events = events[events[:, 2] == 32]
    
    #set time shift parameters
    bashift, pashift, fashift, vashift = calculate_shifts(onset_type)

    # shift the event times
    ba_shifted = mne.event.shift_time_events(ba_events, ids=[4], tshift=bashift, sfreq=raw_filtered.info['sfreq'])
    pa_shifted = mne.event.shift_time_events(pa_events, ids=[8], tshift=pashift, sfreq=raw_filtered.info['sfreq'])
    fa_shifted = mne.event.shift_time_events(fa_events, ids=[16], tshift=fashift, sfreq=raw_filtered.info['sfreq'])
    va_shifted = mne.event.shift_time_events(va_events, ids=[32], tshift=vashift, sfreq=raw_filtered.info['sfreq'])

    ##sort shifted events
    # combine all shifted events into one array (this is important, the events need to be chronological for the categorization to make sense
    combined_shifted_events = np.concatenate((ba_shifted, pa_shifted, fa_shifted, va_shifted))
    #sort them chronologically 
    combined_shifted_events = combined_shifted_events[np.argsort(combined_shifted_events[:, 0])]

    if debugging: 
        print("Shifted event onsets in data (seconds):")
        for event in combined_shifted_events[:25]:  # Only take the first 25 shifted events
            print(f"Event ID: {event[2]}, Onset: {event[0] / raw_filtered.info['sfreq']:.3f} s")

    #event sorting
    # initialize empty arrays/lists for each event type
    ba_events_set = []
    fa_events_set = []
    va_events_set = []

    # Iterate through events and store them in respective arrays
    for event in combined_shifted_events:
        event_code = event[2]  
        if event_code == 4:  
            ba_events_set.append(event)
        elif event_code == 16:  
            fa_events_set.append(event)
        elif event_code == 32:  
            va_events_set.append(event)

    # lists to store sequences of 'pa' events
    pa_sequences = []
    
    # iterate over events to extract sequences of PA events
    i = 0
    while i < len(combined_shifted_events):
        if events[i, 2] == 8:  # Check if current event is 'pa'
            # Start a new sequence
            pa_sequence = [combined_shifted_events[i].tolist()]

            # Continue adding events to the sequence while they are consecutive 'pa' events
            j = i + 1
            while j < len(combined_shifted_events) and combined_shifted_events[j, 2] == 8:
                pa_sequence.append(combined_shifted_events[j].tolist())
                j += 1
            # Store the sequence if it has more than one event
            if len(pa_sequence) > 1:
                pa_sequences.append(pa_sequence)
            # Move index past the current sequence to avoid re-processing
            i = j
        else:
            i += 1
   
    # Initialize lists to store events for each PA occurrence for the current participant
    pa_events_set = []

    # Iterate through sequences and store events in pa_events_set
    for sequence in pa_sequences:
        for event_idx, event in enumerate(sequence, start=1):
            if event_idx == pa_epoch_to_categorize:
                pa_events_set.append(event)      

    # convert lists to NumPy arrays if needed
    ba_events_set = np.array(ba_events_set)
    pa_events_set = np.array(pa_events_set)
    fa_events_set = np.array(fa_events_set)
    va_events_set = np.array(va_events_set)
    
    # print the number of events in each set
    print(f"Number of BA Events: {ba_events_set.shape[0]}")
    print(f"Number of PA Events: {pa_events_set.shape[0]}")
    print(f"Number of FA Events: {fa_events_set.shape[0]}")
    print(f"Number of VA Events: {va_events_set.shape[0]}")
    
    ##bad channel handling 
    if interpolate_bads: 
        # interpolate bad channels
        raw_filtered.interpolate_bads(origin=(0.0, 0.0, 0.0), method=dict(meg="MNE"))
        
    # plot the raw filtered data to see effect of interpolation
    if plot_raw: 
        raw_filtered.plot(n_channels=30, block=True, title=f'Filtered MEG Data {participant_id}')
    
    ##  run ICA
    if ICA_on_raw:
        ica = mne.preprocessing.ICA(n_components=ICA_variance, 
                                    method = 'picard',
                                    fit_params = dict(ortho=False, extended=False),
                                    random_state=13)
         # fit ICA on filtered data
        ica.fit(raw_filtered)
        # then tries to find the ecg artifacts in ica
        ecg_epochs = mne.preprocessing.create_ecg_epochs(raw_filtered,
                                                         reject=None,
                                                         baseline=(None, 0),
                                                         tmin=-0.5,
                                                         tmax=0.5)
        ecg_evoked = ecg_epochs.average()
        ecg_inds, ecg_scores = ica.find_bads_ecg(
            ecg_epochs, method='ctps')
        raw_filtered.load_data()
        ica.exclude = components_to_exclude
        if display_ica_plots:
            ica.plot_sources(raw, show_scrollbars=False, title=participant_id)
            ica.plot_components(title=participant_id)
            ica.plot_scores(ecg_scores, title=participant_id)
            ica.plot_sources(ecg_evoked, title=participant_id)
            ica.plot_overlay(ecg_evoked, title=participant_id)
        print(f"Components excluded: {ica.exclude}") 
        # apply ICA to raw data
        raw_filtered_ICA = ica.apply(raw_filtered)
        if display_ica_plots: 
            raw_filtered.plot(n_channels=30, block=True, title=f'Filtered MEG Data {participant_id}')
    
    ##epoching
    if reject_bad_epochs and ICA_on_raw:
        epochs_ba = mne.Epochs(raw_filtered_ICA, 
                               ba_events_set, 
                               {'ba': 4}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               baseline=baseline, 
                               preload=True)
        epochs_pa = mne.Epochs(raw_filtered_ICA, 
                               pa_events_set, 
                               {'pa': 8}, 
                               tmin=tmin,
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_fa = mne.Epochs(raw_filtered_ICA, 
                               fa_events_set, 
                               {'fa': 16}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_va = mne.Epochs(raw_filtered_ICA, 
                               va_events_set, 
                               {'va': 32},
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        # Print dropped epochs for each participant
        dropped_epochs = {
            'ba': len(epochs_ba.drop_log),
            'pa': len(epochs_pa.drop_log),
            'fa': len(epochs_fa.drop_log),
            'va': len(epochs_va.drop_log)
        }
    elif reject_bad_epochs and ICA_on_epochs:#don't want to baseline here, do it after ICA 
        epochs_ba = mne.Epochs(raw_filtered, 
                               ba_events_set, 
                               {'ba': 4}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               baseline=None, preload=True)
        epochs_pa = mne.Epochs(raw_filtered, 
                               pa_events_set, 
                               {'pa': 8}, 
                               tmin=tmin,
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=None, preload=True)
        epochs_fa = mne.Epochs(raw_filtered, 
                               fa_events_set, 
                               {'fa': 16}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=None, preload=True)
        epochs_va = mne.Epochs(raw_filtered, 
                               va_events_set, 
                               {'va': 32},
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=None, preload=True)
        # Print dropped epochs for each participant
        dropped_epochs = {
            'ba': len(epochs_ba.drop_log),
            'pa': len(epochs_pa.drop_log),
            'fa': len(epochs_fa.drop_log),
            'va': len(epochs_va.drop_log)
        }
        
    else:
        epochs_ba = mne.Epochs(raw_filtered, ba_events_set, {'ba': 4}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa = mne.Epochs(raw_filtered, pa_events_set, {'pa': 8}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_fa = mne.Epochs(raw_filtered, fa_events_set, {'fa': 16}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_va = mne.Epochs(raw_filtered, va_events_set, {'va': 32}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)   

    if ICA_on_epochs:
        # Define a function to run ICA on a specific set of epochs
        n_components = ICA_variance
        method = 'picard'
        max_iter = 1000
        fit_params = dict(fastica_it=5)
        random_state = 13
        def run_ica_on_epochs(epochs, event_name):
            # Create ICA object
            ica = mne.preprocessing.ICA(n_components=n_components, 
                                        method=method, 
                                        max_iter=max_iter, 
                                        fit_params=fit_params, 
                                        random_state=random_state)
            
            # Fit ICA to the epochs
            ica.fit(epochs)
            # Detect ECG artifacts in these epochs
            ecg_epochs = mne.preprocessing.create_ecg_epochs(epochs, 
                                                              reject=None, 
                                                              baseline=(None, -0.02), 
                                                              tmin=-0.5, 
                                                              tmax=0.5)
            ecg_evoked = ecg_epochs.average()
        
            # Find ECG components
            ecg_inds, ecg_scores = ica.find_bads_ecg(ecg_epochs, method='ctps')
            # Exclude the identified ECG components
            ica.exclude = ecg_inds
        
            # display ICA plots
            if display_ica_plots:
                ica.plot_sources(epochs, show_scrollbars=False, title={participant_id})
                ica.plot_components(title={participant_id})
                ica.plot_scores(ecg_scores, title={participant_id})
                ica.plot_sources(ecg_evoked, title={participant_id})
                ica.plot_overlay(ecg_evoked, title={participant_id})
                print(f"Components excluded: {ica.exclude}") 
        
            # Apply ICA to the epochs
            epochs_ica = ica.apply(epochs.copy())
            
            return epochs_ica
        
            # Run ICA on each epoch set individually
            epochs_ba = run_ica_on_epochs(epochs_ba, "BA")
            epochs_pa = run_ica_on_epochs(epochs_pa, "PA")
            epochs_fa = run_ica_on_epochs(epochs_fa, "FA")
            epochs_va = run_ica_on_epochs(epochs_va, "VA")

        # Apply baseline correction to each ICA-corrected epochs
        epochs_ba.apply_baseline(baseline)
        epochs_pa.apply_baseline(baseline)
        epochs_fa.apply_baseline(baseline)
        epochs_va.apply_baseline(baseline)
    
    # Resample epochs 
    if resample_evoked:
        epochs_ba.resample(sfreq=resample_rate)
        epochs_pa.resample(sfreq=resample_rate)
        epochs_fa.resample(sfreq=resample_rate)
        epochs_va.resample(sfreq=resample_rate)

    if dropped_epoch_logging: 
        print(epochs_ba.drop_log)
        epochs_ba.plot_drop_log()
        
    if debugging: 
        # Print the length of epochs
        print(f'Length of epochs_ba: {len(epochs_ba)}')
        
        # To print the time points of each epoch, you can do:
        print(f'Time points for each epoch: {epochs_ba.times}')
        
        # If you want to print the duration of each epoch in seconds:
        epoch_duration = epochs_ba.times[-1] - epochs_ba.times[0]  # Length of one epoch
        print(f'Duration of each epoch (in seconds): {epoch_duration}')

    
    # Count epochs for this participant
    total_epochs_ba += len(epochs_ba)
    total_epochs_pa += len(epochs_pa)
    total_epochs_fa += len(epochs_fa)
    total_epochs_va += len(epochs_va)

    # save epochs data
    epochs_data = {"ba": epochs_ba, "va": epochs_va, "fa": epochs_fa, "pa": epochs_pa}
    for event_type, epoch_data in epochs_data.items():
        epoch_data.save(output_dir / f'{participant_id}_{event_type}_{ICA_suffix}_{reject_suffix}-epo.fif', overwrite=True)
    
    ##creat evoked objects
    # create evoked objects from epochs
    ba_evoked = epochs_ba.average()
    pa_evoked = epochs_pa.average()
    fa_evoked = epochs_fa.average()
    va_evoked = epochs_va.average()
    evokeds = [ba_evoked, pa_evoked, fa_evoked, va_evoked]
    
    # save evoked data
    mne.write_evokeds(output_dir / f'{participant_id}_{ICA_suffix}_{reject_suffix}-ave.fif', list(evokeds), overwrite=True)


    # Define info for the plots
    color_dict = {'pa': 'gray', 'ba': 'blue', 'fa': 'green', 'va': 'red'}
    linestyle_dict = {'pa': '-', 'ba': '-', 'fa': '-', 'va': '-'}
    fig = mne.viz.plot_compare_evokeds(evokeds,
                         ci=False,
                         legend='upper left',
                         show_sensors='upper right',
                         colors=color_dict,
                         linestyles=linestyle_dict,
                         show=show_individual_plots,
                         title=f'{participant_id} {onset_type} onset'
                            ) 
    plt.savefig(f'{plot_directory}/{participant_id}_ERP_{subdirectory}.pdf')
    plt.close()

    if show_individual_plots: 
        # topographic map to check eye activity
        fig, axs = plt.subplots(4, 6, figsize=(16, 12), gridspec_kw={'height_ratios': [1, 1, 1, 1], 'hspace': 0})
        times = [0.250, 0.300, 0.350, 0.400, 0.450, 0.500]
        evokeds[0].plot_topomap(times=times, ch_type='mag', axes=axs[0, :], show=False, colorbar=False)
        evokeds[1].plot_topomap(times=times, ch_type='mag', axes=axs[1, :], show=False, colorbar=False)
        evokeds[2].plot_topomap(times=times, ch_type='mag', axes=axs[2, :], show=False, colorbar=False)
        evokeds[3].plot_topomap(times=times, ch_type='mag', axes=axs[3, :], show=False, colorbar=False)
        for i, label in enumerate(['PA evoked', 'BA evoked', 'FA evoked', 'VA evoked']):
            axs[i, 0].text(-0.1, 1.05, label, transform=axs[i, 0].transAxes, fontsize=12, va='center', ha='right')
        plt.show()
        plt.close()

    # delete variables to free up memory
    del raw, raw_meg, raw_filtered
    del epochs_ba, epochs_pa, epochs_fa, epochs_va, epochs_data
    del ba_evoked, pa_evoked, fa_evoked, va_evoked, evokeds


# Print final epoch counts
print(f"Total BA epochs across all datasets: {total_epochs_ba}")
print(f"Total PA epochs across all datasets: {total_epochs_pa}")
print(f"Total FA epochs across all datasets: {total_epochs_fa}")
print(f"Total VA epochs across all datasets: {total_epochs_va}")
