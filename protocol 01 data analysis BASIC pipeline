#this protocol epochs all BA, FA, and VA events. It epochs a single PA event in sequences of PA. It produces thus approximately three times as many PA evoked objects as the other conditions
#works as intended as of 10/17/2024
import pathlib
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import mne


# define protocol and onset type, ICA, epoch rejection, etc
protocol = 'protocol01'
onset_type = 'consonant'         # 'vowel' or 'consonant' depending on where 0 for the trigger is
debugging = False
trigger_position = 0.00         # change this value to shift away from onset
plot_raw = False
ICA = True                       # if False, skips ICA
ICA_variance = 20                # either percent e.g. .95 or number of components e.g., 40
display_ica_plots = True        # allows for ICA componants to be viewed, if set to false ICA will just run according to predetermiend component selection
reject_bad_epochs = True
dropped_epoch_logging = True   #shows loggs for dropped epochs
interpolate_bads = True
baseline = (None, 0)            # means from the first instant to t = 0
show_individual_plots=False
pa_epoch_to_categorize = 4

# define the parameters for bad epochs
reject_criteria = dict(mag=3000e-15) 
flat_criteria = dict(mag=1e-15) 

# list of participant IDs
participant_ids = ['R2830', #
                   'R2890', #really excellent data and signal, platonic test case
                   'R2896', #
                   'R2897', #
                   'R2900', #
                   'R2906', #
                   'R2915', #
                   'R2968', #
                   'R2976', #
                   'R2996', #
                   'R2997', #
                   'R3005', #
                   'R3007', #
                   'R3008'  #
                  ]

# bad channels dictionary 
bad_channels = ['MEG 056']

# Define participant IDs and their corresponding components to exclude
participant_components = {
    'R2830': [0, 1, 2, 3, 4, 5, 9, 16, 19], #11?
    'R2890': [0, 1, 2, 3, 6, 11, 16, 18, 19],
    'R2896': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 19], #11, 18 noisy data 
    'R2897': [0, 1, 2, 3, 4, 5, 13], #8, 9, 18
    'R2900': [0, 1, 2, 3, 13, 14, 18, 19], 
    'R2906': [0, 1, 2, 3, 4, 5, 6, 12, 13, 18, 19], #13?
    'R2915': [0, 1, 2, 3, 4, 7, 8, 14, 17, 19], #4? 16?
    'R2968': [0, 1, 2, 3, 4, 14, 15, 17, 18, 19],  #5, 17, 9 10?    
    'R2976': [0, 1, 2, 3, 9, 10, 14, 16],  
    'R2996': [0, 1, 2, 3, 4, 9, 18], #8? 
    'R2997': [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 18, 19],  # 11, 13 
    'R3005': [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 16, 17], #18, 19?
    'R3007': [0, 1, 2, 3, 4, 12, 14, 15, 17, 18],  # reject?
    'R3008': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17],  #14, 18? 
}


# define the parameters for the filter
l_freq = .1
h_freq = 30

# define the time limits for the epochs
tmin = -0.1
tmax = 0.8  

# Store total counts of epochs across all participants
total_epochs_ba = 0
total_epochs_pa = 0
total_epochs_fa = 0
total_epochs_va = 0

# load data directory
data_dir = pathlib.Path(f'../../all data/{protocol}')
# define subdirectory based on onset type
subdirectory = "V_onset" if onset_type == 'vowel' else "C_onset"
# ensure the output directory exists
output_dir = pathlib.Path(f'../../out_data/{protocol}/{subdirectory}')
output_dir.mkdir(parents=True, exist_ok=True)
# define file names for saving based on processing variables
ICA_suffix = "ICA" if ICA else ""
reject_suffix = "bad_epochs_rejected" if reject_bad_epochs else ""

# only modify below here for a permanent reason!
# define trigger shifts based on onset type
def calculate_shifts(onset_type):
    if onset_type == 'vowel':
        bashift = 0.190-trigger_position
        pashift = 0.125-trigger_position
        fashift = 0.185-trigger_position
        vashift = 0.215-trigger_position
    elif onset_type == 'consonant':
        bashift = 0.160-trigger_position
        pashift = 0.060-trigger_position
        fashift = 0.100-trigger_position
        vashift = 0.160-trigger_position
    else:
        raise ValueError("Unknown onset_type. Supported values are 'vowel' or 'consonant'.")
    return bashift, pashift, fashift, vashift
    
for participant_id, components_to_exclude in tqdm(participant_components.items(), desc="Processing Participants", unit="participant"):

    ##loading and preprocessing of raw files
    # Load and concatenate raws
    sqd_files = [
        data_dir / f"{participant_id}_trial01.sqd",
        data_dir / f"{participant_id}_trial02.sqd",
        data_dir / f"{participant_id}_trial03.sqd"
    ]
    raws = [mne.io.read_raw_kit(file, preload=True) for file in sqd_files]

    # set bad channels
    for raw in raws:
        raw.info['bads'].extend(bad_channels)
    raw = mne.concatenate_raws(raws)

    # find events
    events = mne.find_events(raw)
    mapping = {4: 'ba', 8: 'pa', 16: 'fa', 32: 'va'} 
    
    if debugging: 
        print("Original event onsets in raw data (seconds):")
        for event in events[:55]:  # Only take the first 25 events
            print(f"Event ID: {event[2]}, Onset: {event[0] / raw.info['sfreq']:.3f} s")

    # create a raw_meg object which excludes all non-meg channels
    raw_meg = raw.copy().pick('meg', exclude='bads')#) 
    # filter the raw data
    raw_filtered = raw_meg.copy().filter(l_freq=l_freq, h_freq=h_freq) 

    # Ensure the sampling frequency 
    desired_sfreq = 1000
    if raw_filtered.info['sfreq'] != desired_sfreq:
        print(f"Downsampling the data from {raw_filtered.info['sfreq']} Hz to {desired_sfreq} Hz.")
        raw_filtered = raw_filtered.resample(sfreq=desired_sfreq)

    ##event mangement
    # time shift events
    # filter for events, this makes four categories of events. you need this to shift times correctly
    ba_events = events[events[:, 2] == 4]
    pa_events = events[events[:, 2] == 8]
    fa_events = events[events[:, 2] == 16]
    va_events = events[events[:, 2] == 32]
    
    #set time shift parameters
    bashift, pashift, fashift, vashift = calculate_shifts(onset_type)

    # shift the event times
    ba_shifted = mne.event.shift_time_events(ba_events, ids=[4], tshift=bashift, sfreq=raw_filtered.info['sfreq'])
    pa_shifted = mne.event.shift_time_events(pa_events, ids=[8], tshift=pashift, sfreq=raw_filtered.info['sfreq'])
    fa_shifted = mne.event.shift_time_events(fa_events, ids=[16], tshift=fashift, sfreq=raw_filtered.info['sfreq'])
    va_shifted = mne.event.shift_time_events(va_events, ids=[32], tshift=vashift, sfreq=raw_filtered.info['sfreq'])

    ##sort shifted events
    # combine all shifted events into one array (this is important, the events need to be chronological for the categorization to make sense
    combined_shifted_events = np.concatenate((ba_shifted, pa_shifted, fa_shifted, va_shifted))
    #sort them chronologically 
    combined_shifted_events = combined_shifted_events[np.argsort(combined_shifted_events[:, 0])]

    if debugging: 
        print("Shifted event onsets in data (seconds):")
        for event in combined_shifted_events[:25]:  # Only take the first 25 shifted events
            print(f"Event ID: {event[2]}, Onset: {event[0] / raw_filtered.info['sfreq']:.3f} s")

        # print number of events and their mapping
        print("Number of events per condition:")
        for code, condition in mapping.items():
            num_events = len(events[events[:, 2] == code])
            print(f"{condition}: {num_events} events")

    #event sorting
    # initialize empty arrays/lists for each event type
    ba_events_set = []
    fa_events_set = []
    va_events_set = []

    # Iterate through events and store them in respective arrays
    for event in combined_shifted_events:
        event_code = event[2]  
        if event_code == 4:  
            ba_events_set.append(event)
        elif event_code == 16:  
            fa_events_set.append(event)
        elif event_code == 32:  
            va_events_set.append(event)

    # lists to store sequences of 'pa' events
    pa_sequences = []
    
    # iterate over events to extract sequences of PA events
    i = 0
    while i < len(combined_shifted_events):
        if events[i, 2] == 8:  # Check if current event is 'pa'
            # Start a new sequence
            pa_sequence = [combined_shifted_events[i].tolist()]

            # Continue adding events to the sequence while they are consecutive 'pa' events
            j = i + 1
            while j < len(combined_shifted_events) and combined_shifted_events[j, 2] == 8:
                pa_sequence.append(combined_shifted_events[j].tolist())
                j += 1
            # Store the sequence if it has more than one event
            if len(pa_sequence) > 1:
                pa_sequences.append(pa_sequence)
            # Move index past the current sequence to avoid re-processing
            i = j
        else:
            i += 1
   
    # Initialize lists to store events for each PA occurrence for the current participant
    pa_events_set = []

    # Iterate through sequences and store events in pa_events_set
    for sequence in pa_sequences:
        for event_idx, event in enumerate(sequence, start=1):
            if event_idx == pa_epoch_to_categorize:
                pa_events_set.append(event)      

    # convert lists to NumPy arrays if needed
    ba_events_set = np.array(ba_events_set)
    pa_events_set = np.array(pa_events_set)
    fa_events_set = np.array(fa_events_set)
    va_events_set = np.array(va_events_set)
    
    # print the number of events in each set
    print(f"Number of BA Events: {ba_events_set.shape[0]}")
    print(f"Number of PA Events: {pa_events_set.shape[0]}")
    print(f"Number of FA Events: {fa_events_set.shape[0]}")
    print(f"Number of VA Events: {va_events_set.shape[0]}")
    
    ##bad channel handling 
    # Identify flat channels by checking for low variance
    variance_threshold = 1e-53
    flat_channels = []
    for ch in raw_filtered.ch_names:
        # Get data for the current channel
        channel_data = raw_filtered.get_data(picks=ch)
        # Calculate the variance of the channel data
        channel_variance = np.var(channel_data)
        # Check if the channel's variance is less than or equal to the threshold
        if channel_variance <= variance_threshold:
            flat_channels.append(ch)
    print("Flat channels identified (low variance):", flat_channels)

    #make flat channels bad
    raw_filtered.info['bads'].extend(flat_channels)

    if interpolate_bads: 
        # interpolate bad channels
        raw_filtered.interpolate_bads(origin=np.array([0.0, 0.0, 0.0]), method=dict(meg="MNE", fnirs="nearest"))
        print(f"Interpolated bad channels: {flat_channels}")
    # Plot the raw filtered data if plot_raw is True
    if plot_raw: 
        raw_filtered.plot(n_channels=30, block=True, title='Filtered MEG Data')
    
    ##  run ICA
    if ICA:
        # ICA Configuration
        n_components = ICA_variance
        method = 'picard'
        max_iter = 1000
        fit_params = dict(fastica_it=5)
        random_state = 13

        ica = mne.preprocessing.ICA(n_components=ICA_variance, 
                                    method=method,
                                    max_iter=max_iter,
                                    fit_params=fit_params,
                                    random_state=random_state)
         # fit ICA on filtered data
        ica.fit(raw_filtered)
         # then tries to find the ecg artifacts in ica
        ecg_epochs = mne.preprocessing.create_ecg_epochs(raw_filtered,
                                                         reject=None,
                                                         baseline=(None, -.02),
                                                         tmin=-0.5,
                                                         tmax=0.5)
        ecg_evoked = ecg_epochs.average()
        ecg_inds, ecg_scores = ica.find_bads_ecg(
            ecg_epochs, method='ctps')
        raw_filtered.load_data()
        ica.exclude = components_to_exclude
        if display_ica_plots:
            ica.plot_sources(raw, show_scrollbars=False)
            ica.plot_components()
            ica.plot_scores(ecg_scores)
            ica.plot_sources(ecg_evoked)
            ica.plot_overlay(ecg_evoked)
        print(f"Components excluded: {ica.exclude}") 
        # apply ICA to raw data
        raw_filtered_ICA = ica.apply(raw_filtered)

   
   
    
    ##epoching
    if reject_bad_epochs:
        epochs_ba = mne.Epochs(raw_filtered_ICA, 
                               ba_events_set, 
                               {'ba': 4}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               baseline=baseline, 
                               preload=True)
        epochs_pa = mne.Epochs(raw_filtered_ICA, 
                               pa_events_set, 
                               {'pa': 8}, 
                               tmin=tmin,
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_fa = mne.Epochs(raw_filtered_ICA, 
                               fa_events_set, 
                               {'fa': 16}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_va = mne.Epochs(raw_filtered_ICA, 
                               va_events_set, 
                               {'va': 32},
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        # Print dropped epochs for each participant
        dropped_epochs = {
            'ba': len(epochs_ba.drop_log),
            'pa': len(epochs_pa.drop_log),
            'fa': len(epochs_fa.drop_log),
            'va': len(epochs_va.drop_log)
        }
    else:
        epochs_ba = mne.Epochs(raw_filtered, ba_events_set, {'ba': 4}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa = mne.Epochs(raw_filtered, pa_events_set, {'pa': 8}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_fa = mne.Epochs(raw_filtered, fa_events_set, {'fa': 16}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_va = mne.Epochs(raw_filtered, va_events_set, {'va': 32}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)   

    # Resample epochs to 250 Hz
    desired_sfreq = 250
    epochs_ba.resample(sfreq=desired_sfreq)
    epochs_pa.resample(sfreq=desired_sfreq)
    epochs_fa.resample(sfreq=desired_sfreq)
    epochs_va.resample(sfreq=desired_sfreq)

    if dropped_epoch_logging: 
        print(epochs_ba.drop_log)
        epochs_ba.plot_drop_log()
        
    if debugging: 
        # Print the length of epochs
        print(f'Length of epochs_ba: {len(epochs_ba)}')
        
        # To print the time points of each epoch, you can do:
        print(f'Time points for each epoch: {epochs_ba.times}')
        
        # If you want to print the duration of each epoch in seconds:
        epoch_duration = epochs_ba.times[-1] - epochs_ba.times[0]  # Length of one epoch
        print(f'Duration of each epoch (in seconds): {epoch_duration}')

    
    # Count epochs for this participant
    total_epochs_ba += len(epochs_ba)
    total_epochs_pa += len(epochs_pa)
    total_epochs_fa += len(epochs_fa)
    total_epochs_va += len(epochs_va)

    # save epochs data
    epochs_data = {"ba": epochs_ba, "va": epochs_va, "fa": epochs_fa, "pa": epochs_pa}
    for event_type, epoch_data in epochs_data.items():
        epoch_data.save(output_dir / f'{participant_id}_{event_type}_{ICA_suffix}_{reject_suffix}-epo.fif', overwrite=True)
    
    ##creat evoked objects
    # create evoked objects from epochs
    ba_evoked = epochs_ba.average()
    pa_evoked = epochs_pa.average()
    fa_evoked = epochs_fa.average()
    va_evoked = epochs_va.average()
    evokeds = [ba_evoked, pa_evoked, fa_evoked, va_evoked]
    
    # save evoked data
    mne.write_evokeds(output_dir / f'{participant_id}_{ICA_suffix}_{reject_suffix}-ave.fif', list(evokeds), overwrite=True)


    # Define info for the plots
    color_dict = {'pa': 'gray', 'ba': 'blue', 'fa': 'green', 'va': 'red'}
    linestyle_dict = {'pa': '-', 'ba': '-', 'fa': '-', 'va': '-'}
    fig = mne.viz.plot_compare_evokeds(evokeds,
                         ci=False,
                         legend='upper left',
                         show_sensors='upper right',
                         colors=color_dict,
                         linestyles=linestyle_dict,
                         show=show_individual_plots
                         title=f'{participant_id} {onset_type} onset'
                            ) 
    plt.savefig(f'{plot_directory}/ERPs_{onset_type}_{participant_id}_{ICA_file}.pdf')
    plt.close()

    if show_individual_plots: 
        # topographic map to check eye activity
        fig, axs = plt.subplots(4, 6, figsize=(16, 12), gridspec_kw={'height_ratios': [1, 1, 1, 1], 'hspace': 0})
        times = [0.250, 0.300, 0.350, 0.400, 0.450, 0.500]
        evokeds[0].plot_topomap(times=times, ch_type='mag', axes=axs[0, :], show=False, colorbar=False)
        evokeds[1].plot_topomap(times=times, ch_type='mag', axes=axs[1, :], show=False, colorbar=False)
        evokeds[2].plot_topomap(times=times, ch_type='mag', axes=axs[2, :], show=False, colorbar=False)
        evokeds[3].plot_topomap(times=times, ch_type='mag', axes=axs[3, :], show=False, colorbar=False)
        for i, label in enumerate(['PA evoked', 'BA evoked', 'FA evoked', 'VA evoked']):
            axs[i, 0].text(-0.1, 1.05, label, transform=axs[i, 0].transAxes, fontsize=12, va='center', ha='right')
        plt.show()
        plt.close()

    # delete variables to free up memory
    del raw, raw_meg, raw_filtered, flat_channels
    del epochs_ba, epochs_pa, epochs_fa, epochs_va, epochs_data
    del ba_evoked, pa_evoked, fa_evoked, va_evoked, evokeds


# Print final epoch counts
print(f"Total BA epochs across all datasets: {total_epochs_ba}")
print(f"Total PA epochs across all datasets: {total_epochs_pa}")
print(f"Total FA epochs across all datasets: {total_epochs_fa}")
print(f"Total VA epochs across all datasets: {total_epochs_va}")
