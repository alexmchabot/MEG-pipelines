#this protocol epochs all BA, FA, and VA events. It epochs a single PA event in sequences of PA. It produces thus approximately three times as many PA evoked objects as the other conditions
#works as intended as of 10/12/2024

import pathlib
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import mne

#date last run: 10/12/2024

# define protocol and onset type
protocol = 'protocol01'
onset_type = 'consonant'          # 'vowel' or 'consonant' depending on where 0 for the trigger is
trigger_position = 0.00      # change this value to shift away from onset
ICA = True                    # if False, skips ICA
ICA_variance = 40            # either percent e.g. .95 or number of components e.g., 40
display_ica_plots = True      #allows for ICA componants to be viewed, if set to false ICA will just run according to predetermiend component selection
reject_bad_epochs = True
baseline = (None, 0)  # means from the first instant to t = 0
special= ''
show_individual_plots=True

pa_epoch_to_categorize = 4

# define the parameters for bad epochs
reject_criteria = dict(mag=5000e-15) 
flat_criteria = dict(mag=1e-18) #from 1e-15

# list of participant IDs
participant_ids = ['R2830', #
                   'R2890', #really excellent data and signal, platonic test case
                   'R2896', #
                   'R2897', #
                   'R2900', #
                   'R2906', #
                   'R2915', #
                   'R2968', #
                   'R2976', #
                   'R2996', #
                   'R2997', #
                   'R3005', #
                   'R3007', #
                   'R3008'  #
                  ]

# mark bad channels
bad_channels = ['MEG 056', 'MEG 086', 'MEG 158', 'MEG 159', 'MEG 160']
#bad_channels_dict = {
#    'R2896': ['MEG 001', 'MEG 002', 'MEG 003', 'MEG 004', 'MEG 005', 'MEG 006', 'MEG 007', 'MEG 011', 'MEG 012', 'MEG 013', 'MEG 014', 'MEG 015', 'MEG 016', 'MEG 017', 'MEG 018', 'MEG 019', 'MEG 022', 'MEG 025', 'MEG 026', 'MEG 027', 'MEG 028', 'MEG 029', 'MEG 030', 'MEG 031', 'MEG 032', 'MEG 033', 'MEG 034', 'MEG 036', 'MEG 038', 'MEG 039', 'MEG 040', 'MEG 042', 'MEG 044', 'MEG 045', 'MEG 047', 'MEG 050', 'MEG 051', 'MEG 052', 'MEG 054', 'MEG 055', 'MEG 056', 'MEG 086', 'MEG 057', 'MEG 058', 'MEG 060', 'MEG 061', 'MEG 062', 'MEG 063', 'MEG 064', 'MEG 066', 'MEG 067', 'MEG 069', 'MEG 070', 'MEG 071', 'MEG 073', 'MEG 075', 'MEG 076', 'MEG 080', 'MEG 081', 'MEG 082', 'MEG 092', 'MEG 095', 'MEG 097', 'MEG 098', 'MEG 100', 'MEG 101', 'MEG 122', 'MEG 123', 'MEG 124', 'MEG 125', 'MEG 127', 'MEG 141', 'MEG 142', 'MEG 144', 'MEG 145'],
#    'R2968': ['MEG 026', 'MEG 054', 'MEG 056', 'MEG 086', 'MEG 057', 'MEG 144'],
#    'R3007': ['MEG 004', 'MEG 026', 'MEG 030', 'MEG 039', 'MEG 040', 'MEG 051', 'MEG 056', 'MEG 086', 'MEG 059', 'MEG 061', 'MEG 062', 'MEG 065', 'MEG 067', 'MEG 072', 'MEG 080', 'MEG 088', 'MEG 090', 'MEG 096', 'MEG 099', 'MEG 103', 'MEG 104', 'MEG 105', 'MEG 106', 'MEG 111', 'MEG 112', 'MEG 113', 'MEG 115', 'MEG 130', 'MEG 132', 'MEG 139', 'MEG 145', 'MEG 149', 'MEG 151', 'MEG 152', 'MEG 154', 'MEG 157']
#}


# Define participant IDs and their corresponding components to exclude
participant_components = {
    'R2830': [0, 1, 2, 3, 6, 10, 19, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39],
    'R2890': [0, 1, 2, 3, 6, 15, 16, 30, 36, 34, 35, 37, 38, 39, 33, 31, 32],
    'R2896': [0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 15, 16, 20, 22, 25, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #!
    'R2897': [0, 1, 2, 3, 4, 5, 6, 15, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
    'R2900': [0, 1, 2, 3, 10, 15, 17, 25, 28, 37, 35, 34, 36, 38, 39], 
    'R2906': [0, 1, 2, 3, 4, 5, 6, 9, 18, 19, 23, 25, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39],
    'R2915': [0, 1, 2, 3, 5, 9, 12, 13, 14, 20, 25, 26, 28, 30, 32, 36, 37, 38, 39],
    'R2968': [0, 1, 2, 4, 5, 6, 7, 8, 10, 15, 16, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #reject 
    'R2976': [0, 1, 2, 3, 10, 20, 26, 27, 29, 32, 33, 34, 35, 36, 38, 37, 39],
    'R2996': [0, 1, 2, 3, 4, 6, 9, 10, 33, 30, 32, 34, 35, 36, 37, 38, 39],
    'R2997': [0, 1, 2, 3, 4, 5, 7, 11, 14, 15, 17, 18, 19, 21, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], #what is this massive spike at @ 200? upper left?
    'R3005': [0, 1, 2, 3, 4, 5, 6, 8, 7, 27, 29, 33, 34, 35, 36, 37, 38, 39],
    'R3007': [0, 1, 2, 3, 4, 8, 9, 14, 18, 32, 33, 34, 35, 36, 38, 39, 37], #reject
    'R3008': [0, 1, 2, 3, 4, 6, 12, 14, 15, 16, 20, 22, 31, 32, 33, 34, 35, 36, 37, 38, 39], #far upper right blob
}


# define the parameters for the filter
l_freq = 1
h_freq = 25

# define the time limits for the epochs
tmin = -0.1
tmax = 0.8  

# create lists to store ERPs for each condition across all participants
ba_erps = []
fa_erps = []
va_erps = []
pa_erps = []

# define subdirectory based on onset type
subdirectory = "V_onset" if onset_type == 'vowel' else "C_onset"

# load data directory
data_dir = pathlib.Path(f'../../all data/{protocol}')

# ensure the output directory exists
output_dir = pathlib.Path(f'../../out_data/{protocol}/{subdirectory}')
output_dir.mkdir(parents=True, exist_ok=True)

# only modify below here for a permanent reason!
# define trigger shifts based on onset type
def calculate_shifts(onset_type):
    if onset_type == 'vowel':
        bashift = 0.190-trigger_position
        pashift = 0.125-trigger_position
        fashift = 0.185-trigger_position
        vashift = 0.215-trigger_position
    elif onset_type == 'consonant':
        bashift = 0.155-trigger_position
        pashift = 0.030-trigger_position
        fashift = 0.060-trigger_position
        vashift = 0.160-trigger_position
    else:
        raise ValueError("Unknown onset_type. Supported values are 'vowel' or 'consonant'.")
    return bashift, pashift, fashift, vashift
    
# Initialize counters for each epoch type
total_epochs_count = {'ba': 0, 'pa': 0, 'fa': 0, 'va': 0}

#initialize counter to get epoch counts
total_dropped_epochs = {'ba': 0, 'pa': 0, 'fa': 0, 'va': 0}


for participant_id, components_to_exclude in tqdm(participant_components.items(), desc="Processing Participants", unit="participant"):
    # load and concatenate raws
    sqd_files = [
        data_dir / f"{participant_id}_trial01.sqd",
        data_dir / f"{participant_id}_trial02.sqd",
        data_dir / f"{participant_id}_trial03.sqd"
    ]
    raws = [mne.io.read_raw_kit(file, preload=True) for file in sqd_files]
    raw = mne.concatenate_raws(raws)

    # ensure the sampling frequency is 250 Hz
    desired_sfreq = 250
    if raw.info['sfreq'] != desired_sfreq:
        print(f"Downsampling the data from {raw.info['sfreq']} Hz to {desired_sfreq} Hz.")
        raw.resample(sfreq=desired_sfreq)

    # set bad channels
    raw.info['bads'] = bad_channels
    # Set bad channels specific to the participant
    #if participant_id in bad_channels_dict:
    #    raw.info['bads'] = bad_channels_dict[participant_id]
        
    # Find events
    events = mne.find_events(raw)
    mapping = {4: 'ba', 8: 'pa', 16: 'fa', 32: 'va'}
        
    # Shift times for each event directly in the raw data
    bashift, pashift, fashift, vashift = calculate_shifts(onset_type)

    # shifts the event times by the appropripriate amount
    ba_shifted = mne.event.shift_time_events(events, ids=[4], tshift=bashift, sfreq=raw.info['sfreq'])
    pa_shifted = mne.event.shift_time_events(events, ids=[8], tshift=pashift, sfreq=raw.info['sfreq']) 
    fa_shifted = mne.event.shift_time_events(events, ids=[16], tshift=fashift, sfreq=raw.info['sfreq'])
    va_shifted = mne.event.shift_time_events(events, ids=[32], tshift=vashift, sfreq=raw.info['sfreq'])

    # annotates the raw data with the shifted times
    ba_annotations = mne.annotations_from_events(ba_shifted, sfreq=raw.info['sfreq'], orig_time=raw.info['meas_date'], event_desc=mapping)
    pa_annotations = mne.annotations_from_events(pa_shifted, sfreq=raw.info['sfreq'], orig_time=raw.info['meas_date'], event_desc=mapping)
    fa_annotations = mne.annotations_from_events(fa_shifted, sfreq=raw.info['sfreq'], orig_time=raw.info['meas_date'], event_desc=mapping)
    va_annotations = mne.annotations_from_events(va_shifted, sfreq=raw.info['sfreq'], orig_time=raw.info['meas_date'], event_desc=mapping)

    # Set combined annotations on raw data
    raw.set_annotations(ba_annotations)
    raw.set_annotations(pa_annotations)
    raw.set_annotations(fa_annotations)
    raw.set_annotations(va_annotations)
    
    # Print original events
    print("Original events:")
    for event_id, event_type in mapping.items():
        events_of_type = events[events[:, 2] == event_id]
        for i in range(min(5, len(events_of_type))):
            event = events_of_type[i]
            print(f"{event_type} event {i+1}: Time {event[0] / raw.info['sfreq']} s")

    # Print shifted events
    print("\nShifted events:")
    for event_id, event_type in mapping.items():
        if event_id == 4:
            shifted_events = ba_shifted
        elif event_id == 8:
            shifted_events = pa_shifted
        elif event_id == 16:
            shifted_events = fa_shifted
        elif event_id == 32:
            shifted_events = va_shifted
    
        events_of_type = shifted_events[shifted_events[:, 2] == event_id]
        for i in range(min(5, len(events_of_type))):
            event = events_of_type[i]
            print(f"{event_type} event {i+1}: Time {event[0] / raw.info['sfreq']} s")
    


    # Create a raw_meg object which excludes all non-meg channels
    raw_meg = raw.pick_types(meg=True, exclude='bads')

    
        # Apply annotations to raw_meg (with shifted times)
    raw_meg.set_annotations(ba_annotations)
    raw_meg.set_annotations(pa_annotations)
    raw_meg.set_annotations(fa_annotations)
    raw_meg.set_annotations(va_annotations)

    # filter the raw data
    raw_filtered = raw_meg.copy().filter(l_freq=l_freq, h_freq=h_freq)

     # print number of events and their mapping
    print("Number of events per condition:")
    for code, condition in mapping.items():
        num_events = len(events[events[:, 2] == code])
        print(f"{condition}: {num_events} events")

    # conditionally run ICA
    if ICA:
        # ICA Configuration
        n_components = ICA_variance
        method = 'picard'
        max_iter = 1000
        fit_params = dict(fastica_it=5)
        random_state = 13

        ica = mne.preprocessing.ICA(n_components=ICA_variance, 
                                    method=method,
                                    max_iter=max_iter,
                                    fit_params=fit_params,
                                    random_state=random_state)
         # fit ICA on filtered data
        ica.fit(raw_filtered)
         # then tries to find the ecg artifacts in ica
        ecg_epochs = mne.preprocessing.create_ecg_epochs(raw_filtered,
                                                         reject=None,
                                                         baseline=(None, -.02),
                                                         tmin=-0.5,
                                                         tmax=0.5)
        ecg_evoked = ecg_epochs.average()
        ecg_inds, ecg_scores = ica.find_bads_ecg(
            ecg_epochs, method='ctps')

        raw_filtered.load_data()
        ica.exclude = components_to_exclude
        if display_ica_plots:
            ica.plot_sources(raw, show_scrollbars=False)
            ica.plot_components()
            ica.plot_scores(ecg_scores)
            ica.plot_sources(ecg_evoked)
            ica.plot_overlay(ecg_evoked)
        print(f"Components excluded: {ica.exclude}") 
        # apply ICA to raw data
        raw_filtered = ica.apply(raw_filtered)

    # initialize empty arrays/lists for each event type
    ba_events_set = []
    fa_events_set = []
    va_events_set = []
    pa_event_set = []

    # Iterate through events and store them in respective arrays
    for event in ba_shifted:
        event_code = event[2]
        if event_code == 4:
            ba_events_set.append(event)

    for event in fa_shifted:
        event_code = event[2]
        if event_code == 16:
            fa_events_set.append(event)

    for event in va_shifted:
        event_code = event[2]
        if event_code == 32:
            va_events_set.append(event)

    # Initialize lists to store sequences of 'pa' events
    pa_sequences = []
    
 # Iterate over events to extract sequences of 'pa' events
    i = 0
    while i < len(pa_shifted):
        if events[i, 2] == 8:  # Check if current event is 'pa'
            # Start a new sequence
            pa_sequence = [pa_shifted[i].tolist()]

            # Continue adding events to the sequence while they are consecutive 'pa' events
            j = i + 1
            while j < len(pa_shifted) and pa_shifted[j, 2] == 8:
                pa_sequence.append(pa_shifted[j].tolist())
                j += 1
        
            # Store the sequence if it has more than one event
            if len(pa_sequence) > 1:
                pa_sequences.append(pa_sequence)
        
            # Move index past the current sequence to avoid re-processing
            i = j
        else:
            i += 1
   
    # Initialize lists to store events for each PA occurrence for the current participant
    pa_events = []

    # Iterate through sequences and store events in respective lists
    for sequence in pa_sequences:
        for event_idx, event in enumerate(sequence, start=1):
            if event_idx == pa_epoch_to_categorize:
                pa_events.append(event)


    # Print the PA event number
    #print(f"PA event number: {len(pa_events)}")
            

    # vonvert lists to NumPy arrays if needed
    ba_events_set = np.array(ba_events_set)
    pa_event_set = np.array(pa_events)
    fa_events_set = np.array(fa_events_set)
    va_events_set = np.array(va_events_set)


    
    if reject_bad_epochs:
        epochs_ba = mne.Epochs(raw_filtered, 
                               ba_events_set, 
                               {'ba': 4}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria, 
                               baseline=baseline, 
                               preload=True)
        epochs_pa = mne.Epochs(raw_filtered, 
                               pa_event_set, 
                               {'pa': 8}, 
                               tmin=tmin,
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_fa = mne.Epochs(raw_filtered, 
                               fa_events_set, 
                               {'fa': 16}, 
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        epochs_va = mne.Epochs(raw_filtered, 
                               va_events_set, 
                               {'va': 32},
                               tmin=tmin, 
                               tmax=tmax, 
                               reject=reject_criteria, 
                               flat=flat_criteria,
                               baseline=baseline, 
                               preload=True)
        # Print dropped epochs for each participant
        dropped_epochs = {
            'ba': len(epochs_ba.drop_log),
            'pa': len(epochs_pa.drop_log),
            'fa': len(epochs_fa.drop_log),
            'va': len(epochs_va.drop_log)
        }
        print(f"{participant_id}: Dropped epochs - ba: {dropped_epochs['ba']}, pa: {dropped_epochs['pa']}, fa: {dropped_epochs['fa']}, va: {dropped_epochs['va']}")


        
        # Update total dropped epochs
        total_dropped_epochs['ba'] += dropped_epochs['ba']
        total_dropped_epochs['pa'] += dropped_epochs['pa']
        total_dropped_epochs['fa'] += dropped_epochs['fa']
        total_dropped_epochs['va'] += dropped_epochs['va']
    
    else:
        epochs_ba = mne.Epochs(raw_filtered, ba_events_set, {'ba': 4}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_pa = mne.Epochs(raw_filtered, pa_event_set, {'pa': 8}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_fa = mne.Epochs(raw_filtered, fa_events_set, {'fa': 16}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True)
        epochs_va = mne.Epochs(raw_filtered, va_events_set, {'va': 32}, tmin=tmin, tmax=tmax, baseline=baseline, preload=True) 

# Print the number of epochs in epochs_pa
#print(f"Number of epochs in epochs_pa: {len(epochs_pa)}")

        # Count epochs and update total counts, sanity check to make cross-check number of epochs per category to be plotted
    total_epochs_count['ba'] += len(epochs_ba)
    total_epochs_count['pa'] += len(epochs_pa)
    total_epochs_count['fa'] += len(epochs_fa)
    total_epochs_count['va'] += len(epochs_va)
    
# Check if epochs were dropped and continue analysis accordingly
    if len(epochs_ba) == 0:
        print(f"No 'ba' epochs remaining after rejection criteria for participant {participant_id}. Skipping analysis.")
        continue
    if len(epochs_pa) == 0:
        print(f"No 'pa' epochs remaining after rejection criteria for participant {participant_id}. Skipping analysis.")
        continue
    if len(epochs_fa) == 0:
        print(f"No 'fa' epochs remaining after rejection criteria for participant {participant_id}. Skipping analysis.")
        continue
    if len(epochs_va) == 0:
        print(f"No 'va' epochs remaining after rejection criteria for participant {participant_id}. Skipping analysis.")
        continue

    
     # create evoked objects from epochs
    ba_evoked = epochs_ba.average()
    pa_evoked = epochs_pa.average()
    fa_evoked = epochs_fa.average()
    va_evoked = epochs_va.average()
    evokeds = [ba_evoked, pa_evoked, fa_evoked, va_evoked]


    # Print the number of epochs in the PA evoked object
    #print(f"Number of epochs in PA evoked object: {pa_evoked.nave}")
    
    # ensure the output directory exists
    output_dir = pathlib.Path(f'../../out_data/{protocol}/{subdirectory}')
    output_dir.mkdir(parents=True, exist_ok=True)

    # define file names for saving based on ICA variable
    file_suffix = "_ICA" if ICA else ""
    reject_suffix = "_bad_epochs_rejected" if reject_bad_epochs else ""
    
    # save epochs data
    epochs_data = {"ba": epochs_ba, "va": epochs_va, "fa": epochs_fa, "pa": epochs_pa}
    for event_type, epoch_data in epochs_data.items():
        epoch_data.save(output_dir / f'{participant_id}_epochs_{event_type}{file_suffix}{reject_suffix}{special}-epo.fif', overwrite=True)
    
    # save evoked data
    mne.write_evokeds(output_dir / f'{participant_id}_evokeds_{file_suffix}{reject_suffix}{special}-ave.fif', list(evokeds), overwrite=True)

    if show_individual_plots:
        
        # Define info for the plots
        color_dict = {'pa': 'gray', 'ba': 'blue', 'fa': 'green', 'va': 'red'}
        linestyle_dict = {'pa': '-', 'ba': '-', 'fa': '-', 'va': '-'}

        #all channels for all participants
        fig = mne.viz.plot_compare_evokeds(evokeds,
                             ci=False,
                             legend='upper left',
                             show_sensors='upper right',
                             colors=color_dict,
                             linestyles=linestyle_dict,
                             title=f'{participant_id} {onset_type} onset'
                                ) 
        plt.show()
        plt.close()

        # produce topographic map to check eye activity
        #create a 3x6 grid of subplots
        fig, axs = plt.subplots(4, 6, figsize=(16, 12), gridspec_kw={'height_ratios': [1, 1, 1, 1], 'hspace': 0})
        times = [0.150, 0.200, 0.250, 0.300, 0.350, 0.400]
        evokeds[0].plot_topomap(times=times, ch_type='mag', axes=axs[0, :], show=False, colorbar=False)
        evokeds[1].plot_topomap(times=times, ch_type='mag', axes=axs[1, :], show=False, colorbar=False)
        evokeds[2].plot_topomap(times=times, ch_type='mag', axes=axs[2, :], show=False, colorbar=False)
        evokeds[3].plot_topomap(times=times, ch_type='mag', axes=axs[3, :], show=False, colorbar=False)
        for i, label in enumerate(['PA evoked', 'BA evoked', 'FA evoked', 'VA evoked']):
            # Place text above the left-most subplot in each row
            axs[i, 0].text(-0.1, 1.05, label, transform=axs[i, 0].transAxes, fontsize=12, va='center', ha='right')
        plt.show()
        plt.close()

    
    # delete variables to free up memory
    del raw, raw_meg, raw_filtered, epochs_ba, epochs_pa, epochs_fa, epochs_va
    del ba_evoked, pa_evoked, fa_evoked, va_evoked, evokeds

# Print the total number of each kind of epoch across all participants
print("Total number of each kind of epoch across all participants:")
for event_type, count in total_epochs_count.items():
    print(f"{event_type}: {count} epochs")

if reject_bad_epochs: 
    # Print total dropped epochs across all participants
    print("Total dropped epochs across all participants:")
    print(f"ba: {total_dropped_epochs['ba']}, pa: {total_dropped_epochs['pa']}, fa: {total_dropped_epochs['fa']}, va: {total_dropped_epochs['va']}")
